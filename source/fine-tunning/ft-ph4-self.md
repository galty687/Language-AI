# 练习：使用自监督学习微调Phi4-mini





## 要求

让 Phi 4 mini 模型**学习微软文档的领域知识和语言风格**，无需人工标注。



## 背景知识

**因果（或自回归）语言建模微调** 是一种针对生成任务的模型训练方法，主要用于训练类似 GPT 的自回归模型。下面详细介绍这种方法的原理与特点：

1. **基本原理**
    在因果语言建模中，模型的目标是根据给定的前文（也就是之前的词语或子词）预测下一个词。训练时，模型逐步接收序列中的每个词，并尝试预测紧随其后的词。这种预测是“自回归”的，因为每个预测都依赖于先前的输出。
2. **与掩码语言模型（MLM）的区别**
   - 因果语言建模：
     - 模型只能看到当前词之前的上下文，因此是单向（从左到右）的。
     - 适用于生成式任务，如对话生成、文章撰写、代码生成等。
   - 掩码语言模型（MLM）：
     - 模型在输入中随机掩盖（mask）一部分词，然后利用两侧的上下文信息来预测被掩盖的词。
     - 这种方式是双向的，常用于理解任务，比如文本分类、问答等。
3. **训练流程**
   - **数据准备**：通常需要大量连续文本数据，将文本切分成适合模型处理的序列。
   - **输入构建**：使用教师强制（Teacher Forcing）方法，即在训练过程中，每一步输入为之前的真实文本，目标是下一个实际出现的词。
   - **损失计算**：通过比较模型预测的概率分布与实际词语的分布来计算损失，并反向传播以更新模型参数。
4. **优点与应用**
   - **连贯性生成**：由于模型专注于生成连续文本，因此在生成长段落或对话时更具连贯性。
   - **适应生成任务**：这类模型特别适合需要逐步生成文本的任务，如机器翻译、对话系统、文本续写等。
   - **训练简洁**：不需要像 MLM 那样随机掩码，训练流程相对直接，数据预处理简单。

总结来说，因果（自回归）语言建模微调是一种专门针对生成任务设计的训练策略，通过预测下一个词来训练模型，使其在生成文本时能够保持语义连贯与一致。







