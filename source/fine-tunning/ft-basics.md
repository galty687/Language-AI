# 微调基础

三种微调方法：

- **自监督学习（Self-supervised learning）**：通过精心策划特定的训练数据集，使其适用于特定应用场景。
- **监督学习（Supervised learning）**：使用输入-输出对（input-output pairs）来指导训练过程。
- **强化学习（Reinforcement learning）**：训练一个奖励模型（reward model）来评估并评分生成文本补全的质量。



## Self-supervised

与大模型的自我训练方式，让其预测下一个词，例如 Listen to your___. （Heart）。

这样可以重新调整每个Token的概率。

场景：

让大模型熟悉某种体裁。







## 常用微调方法

| **微调方法**         | **方式**          | **参数调整**   | **计算成本** | **适用场景**   |
| -------------------- | ----------------- | -------------- | ------------ | -------------- |
| **GROP**             | 软提示 + 梯度优化 | 仅优化提示嵌入 | 低           | 高效任务适配   |
| **Full Fine-tuning** | 全参数微调        | 所有模型参数   | 高           | 需要大规模调整 |
| **LoRA**             | 低秩适配          | 仅优化部分矩阵 | 中等         | 适用于大型模型 |
| **Prefix Tuning**    | 软提示            | 仅优化前缀嵌入 | 低           | 生成任务优化   |
| **Adapter Tuning**   | 适配层            | 仅优化额外模块 | 适中         | 可扩展性强     |