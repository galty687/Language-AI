# 微调表示型大模型

对于非生成类任务，表示型模型常常表现优异。如果我们拥有足够的数据，微调往往能够产生一些性能表现最优的模型。本节，我们将讨论几种微调 BERT 模型的方法和应用：

- 有监督分类。展示了微调分类模型的一般流程。

- 少样本分类。介绍 SetFit，这是一种利用少量训练样本高效微调高性能模型的方法。

- 使用掩码语言模型的持续预训练。将探讨如何继续训练一个预训练模型。

- 命名实体识别。探讨在 token 级别上进行分类的方式。





## 有监督分类



## 少样本分类



## 使用掩码语言模型的持续预训练



## 命名实体识别
