
<!DOCTYPE html>


<html lang="zh-CN" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GESLLLJC6M"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-GESLLLJC6M');
    </script>
    
    <title>使用MLM微调Bert模型 &#8212; 人工智能实践 0.7 文档</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=be9b6ff4" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=447f2b7d"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'fine-tunning/mlm-bert';</script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="练习：使用自监督学习微调Phi4-mini" href="ft-ph4-self.html" />
    <link rel="prev" title="微调表示型大模型" href="ft-rep-models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="zh-CN"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">人工智能实践 0.7 文档</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="搜索" aria-label="搜索" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">搜索</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">课程简介</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1-Intro/intro.html">课程大纲</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1-Intro/resources.html">资源</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1-Intro/terms.html">术语</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">大模型基础</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../2-Basics/setup.html">环境准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2-Basics/llm-basics.html">LLM 基础</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">基于Transformer的自然语言处理</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../3-Practice/nlp-tasks.html">NLP 任务</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3-Practice/transformer-nlp.html">基于HF Transformer的NLP实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3-Practice/classification.html">文本分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3-Practice/clusttering.html">文档聚类</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">语言学基础</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4-Linguistics/linguistics-llm.html">大语言模型与语言学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4-Linguistics/llm-metrics.html">常见大模型评价指标</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4-Linguistics/translation-metrics.html">译文质量评价方法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4-Linguistics/linguistics-intro.html">语言学简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4-Linguistics/applied-linguistics.html">应用语言学</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">课程实践项目</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../5-Projects/projects.html">课程实践项目要求</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5-Projects/evaluating-llms.html">大模型的评估与选择</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5-Projects/evaluate-case.html">评价模型翻译能力</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">提示词</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../6-Prompts/prompts-intro.html">提示词导论</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6-Prompts/prompts-examples.html">提示词案例分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6-Prompts/langchain.html">基于Langchain的提示词开发实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6-Prompts/good-examples.html">提示词案例分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6-Prompts/jail-break.html">提示词越狱</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">微调</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ft-gen-models.html">微调生成式大模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="ft-phi4.html">SFT 微调 Phi-4</a></li>
<li class="toctree-l1"><a class="reference internal" href="ft-rep-models.html">微调表示型大模型</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">使用MLM微调Bert模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="ft-ph4-self.html">练习：使用自监督学习微调Phi4-mini</a></li>
<li class="toctree-l1"><a class="reference internal" href="ft-rl.html">基于人类反馈微调大模型（RLHF + DPO）</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">智能体</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Agents/agents.html">智能体概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Agents/LangGraph.html">基于LangGraph的智能体开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Agents/mcp.html">模型上下文协议 MCP</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">参考答案</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../answers/transformer-practice-answers.html">基于HF Transformer的NLP实践的练习答案</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="下载此页面">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/fine-tunning/mlm-bert.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="下载源文件"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="列印成 PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="全屏模式"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="搜索" aria-label="搜索" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>使用MLM微调Bert模型</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> 目录 </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#masked-language-model-mlm">掩码语言模型（Masked Language Model，MLM）</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">示例数据</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">示例代码</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bert-mlm">使用微软文档文本微调Bert (MLM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-1">Cell 1: 安装依赖</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-2-microsoftdocs-azure-docs">Cell 2: 克隆 MicrosoftDocs/azure-docs 仓库</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-3-markdown">Cell 3: 处理 Markdown 文件</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-4-hugging-face">Cell 4: 从处理后的数据创建 Hugging Face 数据集</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-5-bert">Cell 5: 加载 bert 模型和分词器，并对数据集进行分词</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-6-mlm">Cell 6: 准备用于 MLM 的数据收集器</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-7-trainer">Cell 7: 设置训练参数并初始化 Trainer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-8-mlm">Cell 8: 使用 MLM 目标对模型进行微调</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-9">Cell 9: 保存微调后的模型和分词器</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">准备数据</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jsongoogle-drive">将数据转为json存入Google Drive</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#json-docs-texts">从目标路径中的 JSON 文件中加载 docs_texts</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nsp">下一句预测（NSP）</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">参考资料</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="mlmbert">
<h1>使用MLM微调Bert模型<a class="headerlink" href="#mlmbert" title="Link to this heading">#</a></h1>
<p>下方代码展示了如何使用 Hugging Face Transformers 库对 Bert 模型进行 MLM 微调，并且演示了如何克隆并处理 MicrosoftDocs/azure-docs 仓库中的文档数据作为训练数据。</p>
<p>Google Colab Notebook 地址： <a class="reference external" href="https://colab.research.google.com/drive/1HAnmGSR-tCeLtfRrFaCFzpD65ABWJY2n?usp=sharing"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section id="masked-language-model-mlm">
<h2>掩码语言模型（Masked Language Model，MLM）<a class="headerlink" href="#masked-language-model-mlm" title="Link to this heading">#</a></h2>
<p>微调过程中，输入文本中的 <code class="docutils literal notranslate"><span class="pre">[MASK]</span></code> 标记通常由微调程序自动生成。具体而言，微调程序会按照预设的策略，对输入文本进行处理，随机选择部分词汇进行掩码操作，以训练模型预测被掩码的词汇。</p>
<p><strong>掩码策略</strong></p>
<ol class="arabic simple">
<li><p><strong>掩码比例</strong>：通常选择输入序列中约15%的词汇进行掩码。</p></li>
<li><p><strong>掩码方式</strong>：</p>
<ul class="simple">
<li><p><strong>80%</strong> 的情况下，将选定的词替换为 <code class="docutils literal notranslate"><span class="pre">[MASK]</span></code> 标记。</p></li>
<li><p><strong>10%</strong> 的情况下，保持选定的词不变。</p></li>
<li><p><strong>10%</strong> 的情况下，将选定的词替换为词汇表中的随机词。</p></li>
</ul>
</li>
</ol>
<p>这种策略的目的是使模型不仅能够学习到 <code class="docutils literal notranslate"><span class="pre">[MASK]</span></code> 标记的上下文，还能在面对未被掩码的词或随机替换的词时，增强模型的鲁棒性。在微调过程中，这些掩码操作由程序自动执行，无需人工干预。开发者只需提供原始文本数据，微调程序会根据上述策略自动生成包含 <code class="docutils literal notranslate"><span class="pre">[MASK]</span></code> 标记的训练数据，以训练模型预测被掩码的词汇。</p>
<section id="id1">
<h3>示例数据<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;doc1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Introduction&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Java is one of the most used programming languages, according to Stack Overflow and GitHub. Java Virtual Machine (JVM) offers a mature way to run Java applications efficiently. Azure offers various ways to deploy your Java applications. No matter what types of Java applications you&#39;re running, Azure has a solution. You can choose from batch processes, nanoservices, and microservices, all the way up to Java Enterprise Edition (EE) and Jakarta EE applications. In this module, we look at Java&#39;s powerful features and give an overview of Azure deployment offers. This module is for Java developers and system administrators who have experience with running Java applications. There&#39;s no coding involved in this conceptual module. Learning objectives By the end of this module, you&#39;ll be able to: Differentiate between types of Java applications. Explain the opportunities for Java developers on Azure. Prerequisites Basic development experience in Java or system operating knowledge for Java-based architectures.&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;doc2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Java at Microsoft&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Developers from around the world learn programming with Java, and it remains one of the most used languages among enterprises. It can help you solve business requirements at all levels. With millions of Java developers worldwide, Java&#39;s success speaks for itself. Java is a strategic language of choice on Azure. We support Java developers on multiple levels to deploy their Java applications. No matter what your architecture looks like, Azure has a solution for you; from monolithic applications to microservices or even serverless applications. Microsoft has a high interest in supporting Java and Java on Azure. Did you know that Microsoft is an official contributor to OpenJDK? Microsoft uses Java in many of its products, like LinkedIn, Yammer, Minecraft, and Surface Duo.&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section id="id2">
<h3>示例代码<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>在使用 Hugging Face 的 Transformers 库进行 MLM 训练时，关键在于数据的预处理。这通常<code class="docutils literal notranslate"><span class="pre">DataCollatorForLanguageModeling</span></code> 来实现，该类负责在训练时对输入数据进行随机掩码操作。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>

<span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">mlm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 启用掩码语言模型</span>
    <span class="n">mlm_probability</span><span class="o">=</span><span class="mf">0.15</span>  <span class="c1"># 设置掩码的概率</span>
<span class="p">)</span>

</pre></div>
</div>
<p>在上述代码中，<code class="docutils literal notranslate"><span class="pre">mlm=True</span></code> 表示启用掩码语言模型，<code class="docutils literal notranslate"><span class="pre">mlm_probability=0.15</span></code> 指定了掩码的概率，即随机选择 15% 的词汇进行掩码处理。然后，将此 <code class="docutils literal notranslate"><span class="pre">data_collator</span></code> 传递给 <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>，如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./phi-finetuned&quot;</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>  <span class="c1"># 传入数据整理器</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
<span class="p">)</span>

</pre></div>
</div>
<p>这样，<code class="docutils literal notranslate"><span class="pre">Trainer</span></code> 在训练过程中会自动应用掩码策略。</p>
<p>MLM通过在输入文本中随机掩盖部分词汇，并要求模型根据上下文预测这些被掩盖的词汇来进行训练。在微调阶段，使用特定领域的数据进行训练，模型会学习到该领域的语言特征和用词习惯。这使得模型在处理该领域的文本时，能够更准确地预测词汇，提高生成文本的质量和相关性。因此，MLM微调通过让模型适应特定领域的语言模式，增强了模型在该领域的表现能力。</p>
</section>
</section>
<hr class="docutils" />
<section id="bert-mlm">
<h2>使用微软文档文本微调Bert (MLM)<a class="headerlink" href="#bert-mlm" title="Link to this heading">#</a></h2>
<section id="cell-1">
<h3>Cell 1: 安装依赖<a class="headerlink" href="#cell-1" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> <span class="n">datasets</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-2-microsoftdocs-azure-docs">
<h3>Cell 2: 克隆 MicrosoftDocs/azure-docs 仓库<a class="headerlink" href="#cell-2-microsoftdocs-azure-docs" title="Link to this heading">#</a></h3>
<p>这一步耗时非常长，本次我的耗时约30分钟。为了后续演示方便，随机删去了很多内容，最后只保留了部分文件。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 克隆仓库</span>
<span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">MicrosoftDocs</span><span class="o">/</span><span class="n">azure</span><span class="o">-</span><span class="n">docs</span><span class="o">.</span><span class="n">git</span>

<span class="c1"># 可选：列出部分 Markdown 文件，确认仓库已克隆成功</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">glob</span>
<span class="n">md_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;azure-docs/**/*.md&quot;</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;共找到 </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">md_files</span><span class="p">)</span><span class="si">}</span><span class="s2"> 个 Markdown 文件。&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>输出结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Cloning</span> <span class="n">into</span> <span class="s1">&#39;azure-docs&#39;</span><span class="o">...</span>
<span class="n">remote</span><span class="p">:</span> <span class="n">Enumerating</span> <span class="n">objects</span><span class="p">:</span> <span class="mi">7888510</span><span class="p">,</span> <span class="n">done</span><span class="o">.</span>
<span class="n">remote</span><span class="p">:</span> <span class="n">Counting</span> <span class="n">objects</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">3279</span><span class="o">/</span><span class="mi">3279</span><span class="p">),</span> <span class="n">done</span><span class="o">.</span>
<span class="n">remote</span><span class="p">:</span> <span class="n">Compressing</span> <span class="n">objects</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">508</span><span class="o">/</span><span class="mi">508</span><span class="p">),</span> <span class="n">done</span><span class="o">.</span>
<span class="n">remote</span><span class="p">:</span> <span class="n">Total</span> <span class="mi">7888510</span> <span class="p">(</span><span class="n">delta</span> <span class="mi">2924</span><span class="p">),</span> <span class="n">reused</span> <span class="mi">2986</span> <span class="p">(</span><span class="n">delta</span> <span class="mi">2771</span><span class="p">),</span> <span class="n">pack</span><span class="o">-</span><span class="n">reused</span> <span class="mi">7885231</span> <span class="p">(</span><span class="kn">from</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span>
<span class="n">Receiving</span> <span class="n">objects</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">7888510</span><span class="o">/</span><span class="mi">7888510</span><span class="p">),</span> <span class="mf">24.30</span> <span class="n">GiB</span> <span class="o">|</span> <span class="mf">30.30</span> <span class="n">MiB</span><span class="o">/</span><span class="n">s</span><span class="p">,</span> <span class="n">done</span><span class="o">.</span>
<span class="n">Resolving</span> <span class="n">deltas</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">6123467</span><span class="o">/</span><span class="mi">6123467</span><span class="p">),</span> <span class="n">done</span><span class="o">.</span>
<span class="n">Updating</span> <span class="n">files</span><span class="p">:</span> <span class="mi">100</span><span class="o">%</span> <span class="p">(</span><span class="mi">56225</span><span class="o">/</span><span class="mi">56225</span><span class="p">),</span> <span class="n">done</span><span class="o">.</span>
<span class="n">Found</span> <span class="mi">17449</span> <span class="n">markdown</span> <span class="n">files</span><span class="o">.</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-3-markdown">
<h3>Cell 3: 处理 Markdown 文件<a class="headerlink" href="#cell-3-markdown" title="Link to this heading">#</a></h3>
<p>将所有markdown文件拼接列表数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 读取所有 Markdown 文件，并收集文本（可以根据需要添加清洗步骤）</span>
<span class="n">docs_texts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">md_files</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="c1"># 可选：过滤掉字符数较少的文件，只使用超过200字符的文件</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                <span class="n">docs_texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;读取 </span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s2"> 时出错：</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;从仓库中共收集到 </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_texts</span><span class="p">)</span><span class="si">}</span><span class="s2"> 个文档。&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>从仓库中共收集到 1621 个文档。
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-4-hugging-face">
<h3>Cell 4: 从处理后的数据创建 Hugging Face 数据集<a class="headerlink" href="#cell-4-hugging-face" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>

<span class="c1"># 创建一个包含单个字段 &quot;text&quot; 的数据集</span>
<span class="n">docs_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">docs_texts</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_dataset</span><span class="p">)</span>
</pre></div>
</div>
<p>输出：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Dataset</span><span class="p">({</span>
    <span class="n">features</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span>
    <span class="n">num_rows</span><span class="p">:</span> <span class="mi">1621</span>
<span class="p">})</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-5-bert">
<h3>Cell 5: 加载 bert 模型和分词器，并对数据集进行分词<a class="headerlink" href="#cell-5-bert" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BertForMaskedLM</span>

<span class="c1"># Define the checkpoint string</span>
<span class="n">CHECKPOINT</span> <span class="o">=</span> <span class="s2">&quot;google-bert/bert-base-uncased&quot;</span>

<span class="c1"># Load tokenizer and model from the checkpoint</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">CHECKPOINT</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">CHECKPOINT</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Define the tokenization function (adjust max_length as needed)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>

<span class="c1"># Assuming docs_dataset is already defined, map the tokenization function</span>
<span class="n">tokenized_docs</span> <span class="o">=</span> <span class="n">docs_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>

</pre></div>
</div>
<p>输出：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
tokenizer_config.json: 100%
 48.0/48.0 [00:00&lt;00:00, 5.35kB/s]
config.json: 100%
 570/570 [00:00&lt;00:00, 63.4kB/s]
vocab.txt: 100%
 232k/232k [00:00&lt;00:00, 6.17MB/s]
tokenizer.json: 100%
 466k/466k [00:00&lt;00:00, 10.4MB/s]
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
model.safetensors: 100%
 440M/440M [00:02&lt;00:00, 184MB/s]
BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn&#39;t directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you&#39;re using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you&#39;ll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: [&#39;bert.pooler.dense.bias&#39;, &#39;bert.pooler.dense.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.seq_relationship.weight&#39;]
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Map: 100%
 1621/1621 [00:02&lt;00:00, 587.88 examples/s]
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-6-mlm">
<h3>Cell 6: 准备用于 MLM 的数据收集器<a class="headerlink" href="#cell-6-mlm" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>

<span class="c1"># 创建 MLM 数据收集器，设置 15% 的 mask 概率</span>
<span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-7-trainer">
<h3>Cell 7: 设置训练参数并初始化 Trainer<a class="headerlink" href="#cell-7-trainer" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./bert-azure-docs-mlm&quot;</span><span class="p">,</span>       <span class="c1"># 输出目录</span>
    <span class="n">overwrite_output_dir</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;no&quot;</span><span class="p">,</span>                  <span class="c1"># 如需定期评估，可改为 &quot;steps&quot;</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>                        <span class="c1"># 根据需要调整训练轮次</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>            <span class="c1"># 根据 GPU 容量调整 batch size</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>                            <span class="c1"># 每500步保存一次模型</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>                        <span class="c1"># 最多保存最近2个 checkpoint</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized_docs</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-8-mlm">
<h3>Cell 8: 使用 MLM 目标对模型进行微调<a class="headerlink" href="#cell-8-mlm" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 对处理后的 Azure 文档数据进行 MLM 微调</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<blockquote>
<div><p>需要wandb.ai的key</p>
</div></blockquote>
<p><img alt="wandb-key" src="../_images/wandb-key.png" /></p>
<p>输出：</p>
<div class="highlight-md notranslate"><div class="highlight"><pre><span></span>wandb: WARNING The <span class="sb">`run_name`</span> is currently set to the same value as <span class="sb">`TrainingArguments.output_dir`</span>. If this was not intended, please specify a different run name by setting the <span class="sb">`TrainingArguments.run_name`</span> parameter.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Logging into wandb.ai. (Learn how to deploy a W&amp;B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize
wandb: Paste an API key from your profile and hit enter: ··········
wandb: WARNING If you&#39;re specifying your api key in code, ensure this code is not shared publicly.
wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running <span class="sb">`wandb login`</span> from the command line.
wandb: No netrc file found, creating one.
wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc
wandb: Currently logged in as: galty687 (galty687-peking-university) to https://api.wandb.ai. Use <span class="sb">`wandb login --relogin`</span> to force relogin
Tracking run with wandb version 0.19.8
Run data is saved locally in /content/wandb/run-20250319_085505-fwlzb07r
Syncing run ./phi4-azure-docs-mlm to Weights &amp; Biases (docs)
View project at https://wandb.ai/galty687-peking-university/huggingface
View run at https://wandb.ai/galty687-peking-university/huggingface/runs/fwlzb07r
 [306/306 00:35, Epoch 3/3]
Step	Training Loss
TrainOutput(global_step=306, training_loss=1.0518618315653083, metrics={&#39;train_runtime&#39;: 61.0276, &#39;train_samples_per_second&#39;: 79.685, &#39;train_steps_per_second&#39;: 5.014, &#39;total_flos&#39;: 319991251161600.0, &#39;train_loss&#39;: 1.0518618315653083, &#39;epoch&#39;: 3.0})
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cell-9">
<h3>Cell 9: 保存微调后的模型和分词器<a class="headerlink" href="#cell-9" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">drive</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># 挂载 Google Drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>

<span class="c1"># 定义保存模型和分词器的目标文件夹路径（fine-tuned-models 文件夹中）</span>
<span class="n">dest_folder</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/fine-tuned-models/bert-azure-docs-mlm&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dest_folder</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 保存微调后的模型和分词器到目标路径</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">dest_folder</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">dest_folder</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;模型和分词器已保存到 </span><span class="si">{</span><span class="n">dest_folder</span><span class="si">}</span><span class="s2"> 文件夹中。&quot;</span><span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
<p>输出：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&quot;/content/drive&quot;, force_remount=True).
模型和分词器已保存到 /content/drive/MyDrive/fine-tuned-models/bert-azure-docs-mlm 文件夹中。
</pre></div>
</div>
<p><img alt="stored-model" src="../_images/stored-model.png" /></p>
<p>以上代码分为多个单元格，你可以在 Google Colab 中依次运行。你可以根据实际数据和 GPU 资源，调整 <code class="docutils literal notranslate"><span class="pre">max_length</span></code>、<code class="docutils literal notranslate"><span class="pre">num_train_epochs</span></code>、batch size 等参数。此流程先利用 MLM 目标微调模型，再后续可以根据需要用带有不同风格的 SFT 数据进一步进行微调。</p>
<hr class="docutils" />
<p>实验过程中，有时候因为各种原因会重启session，可以讲微调数据存入Google Drive，节约重复下载的时间。</p>
</section>
<section id="id3">
<h3>准备数据<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>将所有markdown文件读取后，拼接为一个单独的 <code class="docutils literal notranslate"><span class="pre">docs_texts</span></code>列表。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">drive</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span><span class="o">,</span><span class="w"> </span><span class="nn">glob</span>

<span class="c1"># 挂载 Google Drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>

<span class="c1"># 定义目标文件夹路径</span>
<span class="n">dest_folder</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/pure-md-files&#39;</span>

<span class="c1"># 使用 glob 获取目标文件夹中所有 Markdown 文件（根目录下的）</span>
<span class="n">md_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_folder</span><span class="p">,</span> <span class="s1">&#39;*.md&#39;</span><span class="p">))</span>
<span class="n">docs_texts</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">md_files</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="c1"># 过滤掉字符数较少的文件，只使用超过200字符的文件</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                <span class="n">docs_texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;读取 </span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s2"> 时出错：</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;从仓库中共收集到 </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_texts</span><span class="p">)</span><span class="si">}</span><span class="s2"> 个文档。&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="jsongoogle-drive">
<h3>将数据转为json存入Google Drive<a class="headerlink" href="#jsongoogle-drive" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="c1"># 定义目标文件夹路径（已挂载到 Google Drive）</span>
<span class="n">dest_folder</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/pure-md-files&#39;</span>

<span class="c1"># 构造保存文件的完整路径</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_folder</span><span class="p">,</span> <span class="s1">&#39;docs_texts.json&#39;</span><span class="p">)</span>

<span class="c1"># 保存 docs_texts 到目标路径中的 JSON 文件</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">docs_texts</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;docs_texts 已保存到 </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2"> 文件。&quot;</span><span class="p">)</span>

</pre></div>
</div>
</section>
<section id="json-docs-texts">
<h3>从目标路径中的 JSON 文件中加载 docs_texts<a class="headerlink" href="#json-docs-texts" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">drive</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="c1"># 挂载 Google Drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>

<span class="c1"># 定义目标文件夹路径（已挂载到 Google Drive）</span>
<span class="n">dest_folder</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/pure-md-files&#39;</span>
<span class="c1"># 构造文件的完整路径</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_folder</span><span class="p">,</span> <span class="s1">&#39;docs_texts.json&#39;</span><span class="p">)</span>

<span class="c1"># 从目标路径中的 JSON 文件中加载 docs_texts</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">load_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">docs_texts</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;docs_texts 已从 </span><span class="si">{</span><span class="n">load_path</span><span class="si">}</span><span class="s2"> 文件中加载。&quot;</span><span class="p">)</span>

</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="nsp">
<h2>下一句预测（NSP）<a class="headerlink" href="#nsp" title="Link to this heading">#</a></h2>
<p>对于 NSP 任务，需要在数据预处理阶段构造句子对，并为每对句子指定标签（即第二个句子是否为第一个句子的后续句）。这通常需要自定义数据集，并在模型定义时选择支持 NSP 任务的模型架构，例如 <code class="docutils literal notranslate"><span class="pre">BertForPreTraining</span></code>。以下是一个简要的示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertForPreTraining</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BertForPreTraining</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./bert-finetuned&quot;</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">custom_nsp_dataset</span><span class="p">,</span>  <span class="c1"># 自定义的 NSP 数据集</span>
<span class="p">)</span>

</pre></div>
</div>
<p>在此示例中，<code class="docutils literal notranslate"><span class="pre">custom_nsp_dataset</span></code> 是一个包含句子对和对应标签的数据集，<code class="docutils literal notranslate"><span class="pre">BertForPreTraining</span></code> 模型同时支持 MLM 和 NSP 任务。</p>
</section>
<section id="id4">
<h2>参考资料<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/learn/nlp-course/en/chapter7/3">Fine-tuning a masked language model</a></p></li>
</ul>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ft-rep-models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">上一页</p>
        <p class="prev-next-title">微调表示型大模型</p>
      </div>
    </a>
    <a class="right-next"
       href="ft-ph4-self.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">练习：使用自监督学习微调Phi4-mini</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> 目录
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#masked-language-model-mlm">掩码语言模型（Masked Language Model，MLM）</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">示例数据</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">示例代码</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bert-mlm">使用微软文档文本微调Bert (MLM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-1">Cell 1: 安装依赖</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-2-microsoftdocs-azure-docs">Cell 2: 克隆 MicrosoftDocs/azure-docs 仓库</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-3-markdown">Cell 3: 处理 Markdown 文件</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-4-hugging-face">Cell 4: 从处理后的数据创建 Hugging Face 数据集</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-5-bert">Cell 5: 加载 bert 模型和分词器，并对数据集进行分词</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-6-mlm">Cell 6: 准备用于 MLM 的数据收集器</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-7-trainer">Cell 7: 设置训练参数并初始化 Trainer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-8-mlm">Cell 8: 使用 MLM 目标对模型进行微调</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-9">Cell 9: 保存微调后的模型和分词器</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">准备数据</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jsongoogle-drive">将数据转为json存入Google Drive</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#json-docs-texts">从目标路径中的 JSON 文件中加载 docs_texts</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nsp">下一句预测（NSP）</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">参考资料</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
作者： 高志军
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright Zhijun Gao.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>