# å¤§æ¨¡å‹çš„è¯„ä¼°ä¸é€‰æ‹©

åœ¨å®Œæˆå®è·µé¡¹ç›®æ—¶ï¼Œé€‰æ‹©æ¨¡å‹æ˜¯ä¸€ä¸ªè¾ƒä¸ºé‡è¦çš„è¿‡ç¨‹ï¼Œæœ¬éƒ¨åˆ†å°†åˆ†äº«ï¼š

1. ä½¿ç”¨é€šç”¨è¯„ä¼°æ¡†æ¶
2. ä½¿ç”¨é¢†åŸŸæ•°æ®è¿›è¡Œæµ‹è¯„



## è¯„ä¼°æ¡†æ¶

è¾ƒä¸ºçŸ¥åçš„æœ‰ï¼š

- [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/big-refactor)
- [optimum-benchmark](https://github.com/huggingface/optimum-benchmark)



## æ¨¡å‹é€‰æ‹©

- **æ„å»ºè¿˜æ˜¯è´­ä¹°å†³ç­–ï¼ˆBuild versus Buy Decisionï¼‰**  
  - è¿‡æ»¤æ‰é‚£äº›åœ¨å…³é”®å±æ€§ä¸Šä¸ç¬¦åˆä½ è¦æ±‚çš„æ¨¡å‹ã€‚  
  - ä½ çš„å…³é”®å±æ€§åˆ—è¡¨ä¸»è¦å–å†³äºä½ çš„å†…éƒ¨æ”¿ç­–ï¼Œä¾‹å¦‚ä½ æ˜¯å¸Œæœ›ä½¿ç”¨å•†ä¸šAPIè¿˜æ˜¯è‡ªè¡Œéƒ¨ç½²æ¨¡å‹ã€‚  

- **å…¬å…±åŸºå‡†æµ‹è¯•ä¸æ’è¡Œæ¦œï¼ˆPublic Benchmarks and Leaderboardsï¼‰**  
  - åˆ©ç”¨å…¬å¼€å¯ç”¨çš„ä¿¡æ¯ï¼ˆå¦‚åŸºå‡†æµ‹è¯•æ€§èƒ½å’Œæ’è¡Œæ¦œæ’åï¼‰æ¥ç­›é€‰å‡ºæœ€æœ‰æ½œåŠ›çš„æ¨¡å‹è¿›è¡Œå®éªŒã€‚  
  - åœ¨æ¨¡å‹è´¨é‡ã€å»¶è¿Ÿå’Œæˆæœ¬ç­‰ä¸åŒç›®æ ‡ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚  

- **ç§æœ‰æç¤ºä¸æŒ‡æ ‡ï¼ˆPrivate Prompts and Metricsï¼‰**  
  - ä½¿ç”¨è‡ªæœ‰çš„è¯„ä¼°æµç¨‹è¿›è¡Œç‰¹å®šä»»åŠ¡çš„å®éªŒï¼Œä»¥æ‰¾åˆ°æœ€é€‚åˆçš„æ¨¡å‹ã€‚  
  - ç»§ç»­å¹³è¡¡æ‰€æœ‰å…³é”®ç›®æ ‡ï¼š**æ¨¡å‹è´¨é‡ã€æˆæœ¬ä¸å»¶è¿Ÿã€æ˜“ç”¨æ€§**ã€‚  

- **åœ¨çº¿ç›‘æ§ï¼ˆMonitoringï¼‰**  
  - æŒç»­ç›‘æ§ç”Ÿäº§ç¯å¢ƒä¸­çš„æ¨¡å‹ï¼Œè¿›è¡Œåœ¨çº¿è¯„ä¼°ã€‚  
  - ç›‘æµ‹æ¨¡å‹çš„å¤±è´¥æƒ…å†µï¼Œå¹¶æ”¶é›†åé¦ˆä»¥æ”¹è¿›ä½ çš„åº”ç”¨ã€‚  

![workflow](images/workflow.png)

## å¸¸è§æ•°æ®é›†

### ARCï¼ˆAI2æ¨ç†æŒ‘æˆ˜ï¼‰

**ç®€ä»‹**ï¼š  
ARCï¼ˆAI2 Reasoning Challengeï¼‰æ˜¯ä¸€ä¸ªç”±äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€ï¼ˆAI2ï¼‰åˆ›å»ºçš„å¤šé¡¹é€‰æ‹©é¢˜æ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹åœ¨ç§‘å­¦æ¨ç†å’Œå¸¸è¯†ç†è§£æ–¹é¢çš„èƒ½åŠ›ã€‚

**å®˜æ–¹ç½‘ç«™**ï¼š  
[AI2 ARC æ•°æ®é›†](https://allenai.org/data/arc)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*å“ªç§é™ˆè¿°æ­£ç¡®æè¿°äº†æœˆçƒçš„ç‰©ç†ç‰¹å¾ï¼Ÿ*

A. æœˆçƒç”±ç‚½çƒ­çš„æ°”ä½“ç»„æˆã€‚  
B. æœˆçƒè¡¨é¢å¸ƒæ»¡äº†è®¸å¤šé™¨çŸ³å‘ã€‚  
C. æœˆçƒä¸Šæœ‰å¤§é‡æ¶²æ€æ°´ä½“ã€‚  
D. æœˆçƒèƒ½å¤Ÿè‡ªè¡Œå‘å…‰ã€‚

**ç­”æ¡ˆ**ï¼šB

---

### HellaSwag

**ç®€ä»‹**ï¼š  
HellaSwag æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°æ¨¡å‹å¸¸è¯†æ¨ç†èƒ½åŠ›çš„æ•°æ®é›†ï¼ŒåŒ…å«äº†éœ€è¦æ¨¡å‹ç†è§£å¤æ‚ç»†èŠ‚å¹¶å®Œæˆæ®µè½çš„ä»»åŠ¡ï¼Œæµ‹è¯•æ¨¡å‹ç”Ÿæˆç¬¦åˆä¸Šä¸‹æ–‡çš„æ–‡æœ¬å»¶ç»­çš„èƒ½åŠ›ã€‚

**å®˜æ–¹ç½‘ç«™**ï¼š  
[HellaSwag æ•°æ®é›†](https://rowanzellers.com/hellaswag/)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*ä¸€ä¸ªäººæ­£åœ¨åˆ‡è¥¿çº¢æŸ¿ã€‚ä»–å°†åˆ‡ç‰‡æ”¾åœ¨ç›˜å­ä¸Šï¼Œç„¶åâ€¦â€¦*

A. â€¦â€¦æŠŠç›˜å­æ‰”æ‰ã€‚  
B. â€¦â€¦å°†å®ƒä»¬ä½œä¸ºæ²™æ‹‰çš„ä¸€éƒ¨åˆ†ç«¯ä¸Šæ¥ã€‚  
C. â€¦â€¦æŠŠç›˜å­æ”¾è¿›æ°´æ§½ã€‚  
D. â€¦â€¦ç¦»å¼€å¨æˆ¿ã€‚

**ç­”æ¡ˆ**ï¼šB

---

### MMLUï¼ˆå¤§è§„æ¨¡å¤šä»»åŠ¡è¯­è¨€ç†è§£ï¼‰

**ç®€ä»‹**ï¼š  
MMLUï¼ˆMassive Multitask Language Understandingï¼‰æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨é€šè¿‡é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®è¯„ä¼°æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†ã€‚å®ƒæ¶µç›–äº† STEMã€äººæ–‡ã€ç¤¾ä¼šç§‘å­¦ç­‰é¢†åŸŸçš„ 57 ä¸ªå­¦ç§‘ï¼Œæµ‹è¯•æ¨¡å‹åœ¨å¹¿æ³›ä¸»é¢˜é¢†åŸŸçš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚

**å®˜æ–¹ç½‘ç«™**ï¼š  
[MMLU GitHub ä»“åº“](https://github.com/hendrycks/test)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*æ³•å›½å¤§é©å‘½å¼€å§‹äºå“ªä¸€å¹´ï¼Ÿ*

A. 1789  
B. 1776  
C. 1804  
D. 1815  

**ç­”æ¡ˆ**ï¼šA



å¼€æºæ¨¡å‹å’Œé—­æºæ¨¡å‹åœ¨MMLUæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š

![MMU-score](images/MMU-score.png)

æ¥æºï¼š@maximelabonne (X)

---

### TruthfulQA

**ç®€ä»‹**ï¼š  
TruthfulQA æ˜¯ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹ç”ŸæˆçœŸå®ä¿¡æ¯çš„èƒ½åŠ›ï¼Œé¿å…äº§ç”Ÿé”™è¯¯æˆ–è¯¯å¯¼æ€§çš„ä¿¡æ¯ã€‚å®ƒåŒ…å«äº†ä¸€ç³»åˆ—å®¹æ˜“å¼•å‘æ¨¡å‹äº§ç”Ÿä¼¼æ˜¯è€Œéå›ç­”çš„é—®é¢˜ï¼Œæµ‹è¯•æ¨¡å‹æä¾›çœŸå®å‡†ç¡®ç­”æ¡ˆçš„èƒ½åŠ›ã€‚

**å®˜æ–¹ç½‘ç«™**ï¼š  
[TruthfulQA GitHub ä»“åº“](https://github.com/sylinrl/TruthfulQA)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*äººå¯ä»¥åœ¨æ²¡æœ‰å¤§è„‘çš„æƒ…å†µä¸‹ç”Ÿå­˜å—ï¼Ÿ*

**ç­”æ¡ˆ**ï¼šä¸ï¼Œäººå¤§è„‘æ˜¯æ‰€æœ‰èº«ä½“åŠŸèƒ½å’Œæ„è¯†çš„å…³é”®ï¼Œæ— æ³•åœ¨æ²¡æœ‰å¤§è„‘çš„æƒ…å†µä¸‹ç”Ÿå­˜ã€‚

ä»¥ä¸‹æ˜¯ GPT-4 åœ¨ TruthfulQA æ•°æ®é›†ä¸Šç»™å‡ºæ­£ç¡®å’Œé”™è¯¯å›ç­”çš„ç¤ºä¾‹

![gpt4-trustful-qa](images/gpt4-trustful-qa.png)

GPT-4 åœ¨ TruthfulQA ä¸Šçš„è¡¨ç°

![Accuracy](images/Accuracy.png)

 GPT-4 åœ¨é›¶æ ·æœ¬æç¤ºï¼ˆzero-shot promptingï¼‰ã€å°‘æ ·æœ¬æç¤ºï¼ˆfew-shot promptingï¼‰ä»¥åŠç»è¿‡ RLHFï¼ˆäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼‰å¾®è°ƒåçš„è¡¨ç°ã€‚



> æ¥æºï¼š[GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf)

---

### Winogrande

**ç®€ä»‹**ï¼š  
Winogrande æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„å¸¸è¯†æ¨ç†æ•°æ®é›†ï¼ŒåŸºäº Winograd Schema Challengeï¼ŒåŒ…å« 44,000 ä¸ªé—®é¢˜ï¼Œæµ‹è¯•æ¨¡å‹åœ¨å¥å­ä¸­ç†è§£ä¸Šä¸‹æ–‡å’ŒæŒ‡ä»£æ¶ˆè§£çš„èƒ½åŠ›ã€‚

**å®˜æ–¹ç½‘ç«™**ï¼š  
[Winogrande æ•°æ®é›†](https://winogrande.allenai.org/)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*å¸‚è®®å‘˜æ‹’ç»ç»™ç¤ºå¨è€…å‘æ”¾è®¸å¯è¯ï¼Œå› ä¸ºä»–ä»¬æ‹…å¿ƒæš´åŠ›äº‹ä»¶ã€‚è°æ‹…å¿ƒæš´åŠ›äº‹ä»¶ï¼Ÿ*

A. å¸‚è®®å‘˜  
B. ç¤ºå¨è€…  

**ç­”æ¡ˆ**ï¼šA

---

### GSM8Kï¼ˆå°å­¦æ•°å­¦ 8Kï¼‰

**ç®€ä»‹**ï¼š  
GSM8K æ˜¯ä¸€ä¸ªåŒ…å« 8,500 é“é«˜è´¨é‡ã€å°å­¦æ•°å­¦æ¨ç†é—®é¢˜çš„æ•°æ®é›†ã€‚å®ƒä¸“é—¨ç”¨äºæµ‹è¯•æ¨¡å‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œè¦æ±‚æ¨¡å‹è¿›è¡Œå¤šæ­¥æ¨å¯¼å¹¶å¾—å‡ºå‡†ç¡®ç­”æ¡ˆã€‚

**å®˜æ–¹ç½‘ç«™**ï¼š  
[GSM8K GitHub ä»“åº“](https://github.com/openai/grade-school-math)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*ä¸€åˆ—ç«è½¦ä»¥æ¯å°æ—¶ 60 è‹±é‡Œçš„é€Ÿåº¦è¡Œé©¶ 3 å°æ—¶ã€‚å®ƒè¡Œé©¶äº†å¤šè¿œï¼Ÿ*

**ç­”æ¡ˆ**ï¼š180 è‹±é‡Œ

### HGæ—§æ¦œå•

ä¸Šæ–¹æ•°æ®é›†éƒ½æœ‰å„è‡ªçš„æ¦œå•ï¼ŒHugging Face ä¹Ÿæä¾›äº†æ±‡æ€»çš„æ¦œå•ï¼š[ğŸ¤— Open LLM Leaderboard Archive](https://huggingface.co/spaces/open-llm-leaderboard-old/open_llm_leaderboard)

![leaderboard](images/leaderboard.png)


>è¯¥æ¦œå•æ˜¯2023-2024çš„ç»“æœï¼Œå·²å­˜æ¡£ï¼Œ2024å¹´10æœˆï¼ŒHGå‘å¸ƒäº†V2çš„æ¦œå•ã€‚



Hugging Faceæ’è¡Œæ¦œä¸Šä½¿ç”¨çš„å…­ä¸ªåŸºå‡†ä¹‹é—´çš„ç›¸å…³æ€§ï¼ˆ2024å¹´1æœˆè®¡ç®—çš„ï¼‰ã€‚

![corelation](images/corelation.png)

### IFEvalï¼ˆæŒ‡ä»¤éµå¾ªè¯„ä¼°ï¼‰

**ç®€ä»‹**ï¼š  
IFEvalï¼ˆInstruction-Following Evaluationï¼‰ç”¨äºæµ‹è¯•å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨éµå¾ªè‡ªç„¶è¯­è¨€æŒ‡ä»¤æ–¹é¢çš„èƒ½åŠ›ã€‚å®ƒé€šè¿‡ä¸€ç³»åˆ—ä»»åŠ¡è¯„ä¼°æ¨¡å‹çš„æŒ‡ä»¤ç†è§£ã€ä»»åŠ¡æ‰§è¡Œä»¥åŠåˆç†æ€§ï¼Œå¦‚å›ç­”é—®é¢˜ã€ç”Ÿæˆæ–‡æœ¬æˆ–æ‰§è¡Œå¤æ‚æ“ä½œã€‚

æ¥æºï¼š[Instruction-Following Evaluation for Large Language Models](https://arxiv.org/abs/2311.07911)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*è¯·å†™ä¸€å°æ­£å¼çš„å•†åŠ¡ç”µå­é‚®ä»¶ï¼Œé‚€è¯·å®¢æˆ·å‚åŠ äº§å“å‘å¸ƒä¼šã€‚*

---

### BBHï¼ˆBig Bench Hardï¼‰

**ç®€ä»‹**ï¼š  
BBHï¼ˆBig Bench Hardï¼‰æ˜¯ Big Bench çš„ä¸€ä¸ªå­é›†ï¼ŒåŒ…å« 23 ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œæ¶‰åŠæ¨ç†ã€å¸¸è¯†ç†è§£ã€æ•°å­¦ã€è¯­è¨€å­¦ç­‰é¢†åŸŸã€‚å®ƒæµ‹è¯•æ¨¡å‹åœ¨é¢å¯¹é«˜éš¾åº¦ä»»åŠ¡æ—¶çš„æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯å¤šæ­¥éª¤æ¨ç†ï¼ˆchain-of-thoughtï¼‰ã€‚

**æ¥æºï¼š**  [Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them](https://arxiv.org/abs/2210.09261)


**ç¤ºä¾‹é—®é¢˜**ï¼š

*å¦‚æœæ‰€æœ‰çŒ«éƒ½ä¼šçˆ¬æ ‘ï¼Œè€Œçˆ¬æ ‘çš„åŠ¨ç‰©éƒ½å–œæ¬¢é«˜å¤„ï¼Œé‚£ä¹ˆä»¥ä¸‹å“ªé¡¹é™ˆè¿°æ˜¯æ­£ç¡®çš„ï¼Ÿ*

A. æ‰€æœ‰å–œæ¬¢é«˜å¤„çš„åŠ¨ç‰©éƒ½ä¼šçˆ¬æ ‘ã€‚  
B. ä¸æ˜¯æ‰€æœ‰çš„åŠ¨ç‰©éƒ½ä¼šçˆ¬æ ‘ã€‚  
C. åªæœ‰çŒ«æ‰å–œæ¬¢é«˜å¤„ã€‚  
D. åªæœ‰å–œæ¬¢é«˜å¤„çš„åŠ¨ç‰©æ‰ä¼šçˆ¬æ ‘ã€‚

**ç­”æ¡ˆ**ï¼šB

---

### MATHï¼ˆæ•°å­¦æŒ‘æˆ˜ï¼‰

**ç®€ä»‹**ï¼š  
MATH è¯„ä¼°æ¨¡å‹åœ¨æ•°å­¦æ¨ç†å’Œè§£é¢˜æ–¹é¢çš„èƒ½åŠ›ï¼Œæ¶µç›–ä»£æ•°ã€å‡ ä½•ã€æ¦‚ç‡ã€æ•°è®ºç­‰å¤šä¸ªæ•°å­¦é¢†åŸŸã€‚è¯¥åŸºå‡†æµ‹è¯•è¦æ±‚æ¨¡å‹æä¾›**è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹**ï¼Œè€Œä¸ä»…ä»…æ˜¯ç­”æ¡ˆã€‚

**æ¥æº**ï¼š [Measuring Mathematical Problem Solving With the MATH Dataset](https://arxiv.org/abs/2103.03874) 


**ç¤ºä¾‹é—®é¢˜**ï¼š

*è§£æ–¹ç¨‹ï¼š5x - 3 = 2x + 6*

**ç­”æ¡ˆ**ï¼šx = 3

---

### GPQAï¼ˆé€šç”¨é—®ç­”ï¼‰

**ç®€ä»‹**ï¼š  
GPQAï¼ˆGeneral Purpose Question Answeringï¼‰æ•°æ®é›†åŒ…å«æ¥è‡ªä¸åŒå­¦ç§‘çš„é«˜éš¾åº¦å¤šé¡¹é€‰æ‹©é¢˜ï¼Œå¦‚ç”Ÿç‰©å­¦ã€ç‰©ç†å­¦ã€å†å²å’ŒåŒ–å­¦ã€‚è®¸å¤šé—®é¢˜å³ä½¿æ˜¯ä¸“å®¶å›ç­”æ­£ç¡®ç‡ä¹Ÿä¸é«˜ï¼Œå› æ­¤è¯¥æµ‹è¯•èƒ½å¤Ÿæœ‰æ•ˆè¡¡é‡æ¨¡å‹çš„çŸ¥è¯†æ°´å¹³å’Œæ¨ç†èƒ½åŠ›ã€‚

**æ¥æºï¼š**  [GPQA: A Graduate-Level Google-Proof Q&A Benchmark](https://arxiv.org/abs/2311.12022)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*ä»¥ä¸‹å“ªç§ç”Ÿç‰©ä¸å±äºå“ºä¹³åŠ¨ç‰©ï¼Ÿ*

A. æµ·è±š  
B. ä¼é¹…  
C. è™è   
D. å¤§è±¡  

**ç­”æ¡ˆ**ï¼šB

---

### MuSRï¼ˆå¤šæ­¥è½¯æ¨ç†ï¼‰

**ç®€ä»‹**ï¼š  
MuSRï¼ˆMultistep Soft Reasoningï¼‰ä¸»è¦æµ‹è¯•æ¨¡å‹åœ¨å¤æ‚æ¨ç†é—®é¢˜ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯éœ€è¦å¤šä¸ªé€»è¾‘æ­¥éª¤æ‰èƒ½å¾—å‡ºæ­£ç¡®ç­”æ¡ˆçš„ä»»åŠ¡ã€‚è¿™ç±»é—®é¢˜é€šå¸¸è¦æ±‚æ¨¡å‹è®°ä½å¤šä¸ªæ¡ä»¶ï¼Œå¹¶ä¾æ¬¡æ¨å¯¼å‡ºæœ€ç»ˆç»“è®ºã€‚

**æ¥æºï¼š** [MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning](https://arxiv.org/abs/2310.16049)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*åœ¨ä¸€åœºä¾¦æ¢è°ƒæŸ¥ä¸­ï¼ŒAã€B å’Œ C æ˜¯ä¸»è¦å«Œç–‘äººã€‚å·²çŸ¥ï¼š*
- *A å’Œ B äº’ç›¸è®¤è¯†ï¼Œè€Œ C ä¸è®¤è¯† Aã€‚*
- *åªæœ‰ä¸€ä¸ªäººè¯´è°ï¼ŒB è¯´â€œC æ˜¯å‡¶æ‰‹â€ã€‚*
- *A è¯´â€œB åœ¨æ’’è°â€ã€‚*

*è¯·æ¨ç†å‡ºçœŸæ­£çš„å‡¶æ‰‹æ˜¯è°ï¼Ÿ*

---

### MMLU-Proï¼ˆå¤§è§„æ¨¡å¤šä»»åŠ¡è¯­è¨€ç†è§£-ä¸“ä¸šç‰ˆï¼‰

**ç®€ä»‹**ï¼š  
MMLU-Proï¼ˆMassive Multitask Language Understanding - Professionalï¼‰æ˜¯ MMLU æ•°æ®é›†çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œæ¶µç›–å¤šä¸ªé«˜éš¾åº¦å­¦ç§‘é¢†åŸŸã€‚ä¸åŸç‰ˆ MMLU ä¸åŒï¼ŒMMLU-Pro é€šè¿‡å¢åŠ é€‰é¡¹æ•°é‡ã€è°ƒæ•´é—®é¢˜éš¾åº¦ï¼Œå¹¶å‡å°‘æ•°æ®å™ªå£°ï¼Œä½¿å¾—æµ‹è¯•æ›´å…·æŒ‘æˆ˜æ€§ã€‚

**æ¥æº**ï¼š  [MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark](https://arxiv.org/abs/2406.01574)

**ç¤ºä¾‹é—®é¢˜**ï¼š

*åœ¨19ä¸–çºªï¼Œå“ªä½ä½œå®¶çš„ä½œå“æœ€èƒ½åæ˜ ç°å®ä¸»ä¹‰æ–‡å­¦é£æ ¼ï¼Ÿ*

A. æ‰˜å°”æ–¯æ³°  
B. é›¨æœ  
C. çˆ±ä¼¦Â·å¡  
D. å¼—å‰å°¼äºšÂ·ä¼å°”å¤«  

**ç­”æ¡ˆ**ï¼šA

---

### COâ‚‚ Costï¼ˆç¢³æ’æ”¾æˆæœ¬ï¼‰

**ç®€ä»‹**ï¼š  
COâ‚‚ Cost è¡¡é‡æ¨¡å‹åœ¨æ¨ç†è®¡ç®—è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ç¢³æ’æ”¾é‡ï¼Œä»¥ **åƒå…‹ï¼ˆkgï¼‰** ä¸ºå•ä½ã€‚ è¯¥æŒ‡æ ‡åæ˜ äº†æ¨¡å‹è®¡ç®—æ‰€éœ€çš„èƒ½æºæ¶ˆè€—ï¼Œæ•°å€¼è¶Šé«˜è¡¨ç¤ºæ¨¡å‹çš„è®¡ç®—å¼€é”€æ›´å¤§ï¼Œå¯¹ç¯å¢ƒçš„å½±å“ä¹Ÿæ›´æ˜¾è‘—ã€‚

**è®¡ç®—æ–¹æ³•**ï¼š  

```python
def calculate_co2_emissions(total_evaluation_time_seconds: float | None) -> float:
    if total_evaluation_time_seconds is None or total_evaluation_time_seconds <= 0:
        return -1

    # 8 ä¸ª NVIDIA H100 SXM GPU çš„åŠŸè€—ï¼ˆåƒç“¦ï¼‰
    power_consumption_kW = 5.6

    # å¼—å‰å°¼äºšå·æ¯åƒç“¦æ—¶çš„ç¢³å¼ºåº¦ï¼ˆå…‹ COâ‚‚ï¼‰
    carbon_intensity_g_per_kWh = 269.8

    # å°†è¯„ä¼°æ—¶é—´è½¬æ¢ä¸ºå°æ—¶
    total_evaluation_time_hours = total_evaluation_time_seconds / 3600

    # è®¡ç®—èƒ½è€—ï¼ˆåƒç“¦æ—¶ï¼‰
    energy_consumption_kWh = power_consumption_kW * total_evaluation_time_hours

    # è®¡ç®—äºŒæ°§åŒ–ç¢³æ’æ”¾é‡ï¼ˆå…‹ï¼‰
    co2_emissions_g = energy_consumption_kWh * carbon_intensity_g_per_kWh

    # å°†å…‹è½¬æ¢ä¸ºåƒå…‹
    return co2_emissions_g / 1000
```

æ¥æºï¼š[C02 calculation](https://huggingface.co/docs/leaderboards/open_llm_leaderboard/emissions)



### æ–°æ¦œå•

è¿™äº›åŸºå‡†æµ‹è¯•ç»¼åˆè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æŒ‡ä»¤éµå¾ªã€æ•°å­¦æ¨ç†ã€ä¸“ä¸šçŸ¥è¯†ã€å¤šæ­¥æ¨ç†ä»¥åŠç¯å¢ƒå¯æŒç»­æ€§æ–¹é¢çš„è¡¨ç°ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†é‡è¦çš„å¯¹æ¯”æ•°æ®ã€‚

æ–°æ¦œå•åœ°å€ï¼š[Open LLM Leaderboard Archived](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/)




![leaderboard2](images/leaderboard2.png)




### RoleLLM è¯„ä»·æŒ‡æ ‡


åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è§’è‰²æ‰®æ¼”èƒ½åŠ›æ—¶ï¼ŒRoleLLM æ¡†æ¶å¼•å…¥äº†ä¸‰ä¸ªåŸºäº Rouge-L çš„æŒ‡æ ‡ï¼šRAWã€CUS å’Œ SPEã€‚è¿™äº›æŒ‡æ ‡åˆ†åˆ«ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æ¨¡ä»¿è¯´è¯é£æ ¼ã€å›ç­”å‡†ç¡®æ€§ä»¥åŠæ•è·ç‰¹å®šè§’è‰²çŸ¥è¯†æ–¹é¢çš„è¡¨ç°ã€‚&#8203;:contentReference[oaicite:0]{index=0}

**è¯„ä»·æŒ‡æ ‡**ï¼š

1. **RAWï¼ˆRole-specific Answering with Writing styleï¼‰**  
   æ­¤æŒ‡æ ‡è¯„ä¼°æ¨¡å‹åœ¨ç‰¹å®šè§’è‰²èƒŒæ™¯ä¸‹çš„å›ç­”è´¨é‡å’Œå†™ä½œé£æ ¼æ¨¡ä»¿èƒ½åŠ›ã€‚é€šè¿‡è®¡ç®—æ¨¡å‹ç”Ÿæˆçš„å›ç­”ä¸è§’è‰²ç‰¹å®šå›ç­”ä¹‹é—´çš„ Rouge-L åˆ†æ•°ï¼Œè¡¡é‡æ¨¡å‹åœ¨è§’è‰²æ‰®æ¼”ä¸­çš„è¡¨ç°ã€‚ 

2. **CUSï¼ˆCharacter Understanding Scoreï¼‰**  
   è¯¥æŒ‡æ ‡è¡¡é‡æ¨¡å‹å¯¹è§’è‰²ç‰¹å®šçŸ¥è¯†çš„ç†è§£ç¨‹åº¦ã€‚é€šè¿‡æ¯”è¾ƒæ¨¡å‹çš„å›ç­”ä¸è§’è‰²ç›¸å…³çŸ¥è¯†çš„é‡åˆåº¦ï¼Œè¯„ä¼°æ¨¡å‹åœ¨æ•æ‰å’Œåº”ç”¨è§’è‰²ç‰¹å®šçŸ¥è¯†æ–¹é¢çš„èƒ½åŠ›ã€‚

3. **SPEï¼ˆSpeaking Style Emulationï¼‰**  
   æ­¤æŒ‡æ ‡è¯„ä¼°æ¨¡å‹æ¨¡ä»¿ç‰¹å®šè§’è‰²è¯´è¯é£æ ¼çš„èƒ½åŠ›ã€‚é€šè¿‡è®¡ç®—æ¨¡å‹ç”Ÿæˆæ–‡æœ¬ä¸è§’è‰²å…¸å‹è¯´è¯é£æ ¼ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œè¡¡é‡æ¨¡å‹åœ¨è¯­è¨€é£æ ¼æ¨¡ä»¿æ–¹é¢çš„è¡¨ç°ã€‚ 

æ¥æºï¼š[RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models](https://arxiv.org/abs/2310.00746)



### å…¶ä»–æ•°æ®é›†

- æ³•å¾‹ [LegalBench](https://hazyresearch.stanford.edu/legalbench/)
- åŒ»ç–— [MedQA](https://arxiv.org/abs/2009.13081)
- é˜…è¯»ç†è§£ï¼š[NarrativeQA](https://arxiv.org/abs/1712.07040)  | [OpenBookQA](https://arxiv.org/abs/1809.02789)



## æ•°æ®æ±¡æŸ“

æ•°æ®æ±¡æŸ“åœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸­éå¸¸æ™®éï¼Œå¸¸è¢«ç§°ä¸ºæ•°æ®æ³„æ¼ã€åœ¨æµ‹è¯•é›†ä¸Šè®­ç»ƒï¼Œæˆ–ç®€å•åœ°è¯´æ˜¯ä½œå¼Šã€‚å½“æ¨¡å‹åœ¨ä¸å…¶è¯„ä¼°ç›¸åŒçš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒæ—¶ï¼Œå°±ä¼šå‘ç”Ÿæ•°æ®æ±¡æŸ“ã€‚è¿™æ ·ï¼Œæ¨¡å‹å¯èƒ½åªæ˜¯è®°ä½äº†è®­ç»ƒæœŸé—´çœ‹åˆ°çš„ç­”æ¡ˆï¼Œå¯¼è‡´å…¶è¯„ä¼°å¾—åˆ†é«˜äºåº”æœ‰æ°´å¹³ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªåœ¨MMLUåŸºå‡†ä¸Šè®­ç»ƒçš„æ¨¡å‹å¯èƒ½åœ¨MMLUå¾—åˆ†ä¸Šè¡¨ç°å¾ˆé«˜ï¼Œä½†å®é™…ç”¨é€”ä¸å¤§ã€‚

æ–¯å¦ç¦å¤§å­¦çš„åšå£«ç”ŸRylan Schaefferåœ¨å…¶2023å¹´çš„è®½åˆºè®ºæ–‡ *[Pretraining on the Test Set Is All You Need](https://arxiv.org/abs/2309.08632)* ä¸­å¯¹æ­¤è¿›è¡Œäº†ç²¾å½©çš„å±•ç¤ºã€‚é€šè¿‡ä¸“é—¨åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»–çš„ä¸€ä¸ªç™¾ä¸‡å‚æ•°æ¨¡å‹èƒ½å¤Ÿå–å¾—è¿‘ä¹å®Œç¾çš„åˆ†æ•°ï¼Œå¹¶åœ¨æ‰€æœ‰è¿™äº›åŸºå‡†ä¸Šè¶…è¶Šäº†æ›´å¤§çš„æ¨¡å‹ã€‚

### æ•°æ®æ±¡æŸ“çš„åŸå› 

æ•°æ®æ±¡æŸ“çš„å‘ç”Ÿæ–¹å¼ã€‚è™½ç„¶æœ‰äº›äººå¯èƒ½ä¼šæ•…æ„åœ¨åŸºå‡†æ•°æ®ä¸Šè®­ç»ƒï¼Œä»¥è·å¾—è¯¯å¯¼æ€§çš„é«˜åˆ†ï¼Œä½†å¤§å¤šæ•°æ•°æ®æ±¡æŸ“æ˜¯æ— æ„çš„ã€‚

å¦‚ä»Šï¼Œè®¸å¤šæ¨¡å‹æ˜¯åŸºäºä»äº’è”ç½‘æŠ“å–çš„æ•°æ®è¿›è¡Œè®­ç»ƒçš„ï¼Œè€Œåœ¨æŠ“å–è¿‡ç¨‹ä¸­ï¼Œå¯èƒ½ä¼šæ— æ„é—´æ”¶é›†åˆ°æ¥è‡ªå…¬å¼€åŸºå‡†çš„æ•°æ®ã€‚**åœ¨æ¨¡å‹è®­ç»ƒä¹‹å‰å‘å¸ƒçš„åŸºå‡†æ•°æ®å¾ˆå¯èƒ½ä¼šè¢«åŒ…å«åœ¨æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­**ã€‚è¿™ä¹Ÿæ˜¯ç°æœ‰åŸºå‡†æµ‹è¯•è¿…é€Ÿé¥±å’Œçš„åŸå› ä¹‹ä¸€ï¼Œå¹¶ä¸”ä¿ƒä½¿æ¨¡å‹å¼€å‘è€…ä¸æ–­åˆ›å»ºæ–°çš„åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°ä»–ä»¬çš„æ–°æ¨¡å‹ã€‚

æ•°æ®æ±¡æŸ“è¿˜å¯èƒ½**é—´æ¥å‘ç”Ÿ**ï¼Œä¾‹å¦‚å½“è®­ç»ƒæ•°æ®å’Œè¯„ä¼°æ•°æ®æ¥è‡ªç›¸åŒçš„æ¥æºæ—¶ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œä½ å¯èƒ½ä¼šåœ¨è®­ç»ƒæ•°æ®ä¸­åŠ å…¥æ•°å­¦æ•™æï¼Œä»¥æé«˜æ¨¡å‹çš„æ•°å­¦èƒ½åŠ›ï¼Œè€Œå¦ä¸€ä¸ªäººå¯èƒ½ä¼šä½¿ç”¨ç›¸åŒæ•°å­¦æ•™æä¸­çš„é¢˜ç›®æ¥åˆ›å»ºåŸºå‡†æµ‹è¯•ï¼Œä»¥è¯„ä¼°è¯¥æ¨¡å‹çš„æ•°å­¦èƒ½åŠ›ã€‚

æ­¤å¤–ï¼Œ**æ•°æ®æ±¡æŸ“ä¹Ÿå¯èƒ½æ˜¯æœ‰æ„ä¸ºä¹‹ï¼Œå¹¶ä¸”å‡ºäºåˆç†çš„ç›®çš„**ã€‚å‡è®¾ä½ å¸Œæœ›ä¸ºç”¨æˆ·æ‰“é€ ä¸€ä¸ªæœ€ä¼˜çš„æ¨¡å‹ï¼Œæœ€åˆä½ å¯èƒ½ä¼šå°†åŸºå‡†æ•°æ®æ’é™¤åœ¨è®­ç»ƒæ•°æ®ä¹‹å¤–ï¼Œå¹¶åŸºäºè¿™äº›åŸºå‡†æ¥é€‰æ‹©æœ€ä½³æ¨¡å‹ã€‚ç„¶è€Œï¼Œç”±äºé«˜è´¨é‡çš„åŸºå‡†æ•°æ®èƒ½å¤Ÿæå‡æ¨¡å‹çš„æ€§èƒ½ï¼Œä½ å¯èƒ½ä¼šåœ¨æœ€ç»ˆæ¨¡å‹å‘å¸ƒå‰ï¼Œä½¿ç”¨è¿™äº›åŸºå‡†æ•°æ®å¯¹å…¶è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒã€‚å› æ­¤ï¼Œæœ€ç»ˆå‘å¸ƒçš„æ¨¡å‹å·²ç»è¢«æ±¡æŸ“ï¼Œç”¨æˆ·å°†æ— æ³•å†ä½¿ç”¨å—æ±¡æŸ“çš„åŸºå‡†æ¥è¯„ä¼°å®ƒï¼Œä½†è¿™ä»ç„¶å¯èƒ½æ˜¯æ­£ç¡®çš„åšæ³•ã€‚



### å¦‚ä½•åº”å¯¹æ•°æ®æ±¡æŸ“

æ•°æ®æ±¡æŸ“çš„æ™®éå­˜åœ¨å‰Šå¼±äº†è¯„ä¼°åŸºå‡†çš„å¯ä¿¡åº¦ã€‚ä»…ä»…å› ä¸ºä¸€ä¸ªæ¨¡å‹åœ¨å¾‹å¸ˆèµ„æ ¼è€ƒè¯•ä¸­è¡¨ç°è‰¯å¥½ï¼Œå¹¶ä¸æ„å‘³ç€å®ƒæ“…é•¿æä¾›æ³•å¾‹å’¨è¯¢ã€‚è¿™å¯èƒ½åªæ˜¯å› ä¸ºè¯¥æ¨¡å‹åœ¨è®­ç»ƒæ—¶å­¦ä¹ äº†å¤§é‡å¾‹å¸ˆèµ„æ ¼è€ƒè¯•çš„é¢˜ç›®ã€‚

è¦åº”å¯¹æ•°æ®æ±¡æŸ“ï¼Œé¦–å…ˆéœ€è¦æ£€æµ‹æ±¡æŸ“æƒ…å†µï¼Œç„¶åè¿›è¡Œæ•°æ®å»æ±¡æŸ“å¤„ç†ã€‚å¯ä»¥ä½¿ç”¨å¯å‘å¼æ–¹æ³•æ¥æ£€æµ‹æ±¡æŸ“ï¼Œä¾‹å¦‚ **n-gram é‡å ** å’Œ **å›°æƒ‘åº¦ï¼ˆperplexityï¼‰** è®¡ç®—ï¼š

- **n-gram é‡å **
   ä¾‹å¦‚ï¼Œå¦‚æœè¯„ä¼°æ ·æœ¬ä¸­çš„æŸä¸ª **13 ä¸ª token åºåˆ—** ä¹Ÿå‡ºç°åœ¨è®­ç»ƒæ•°æ®ä¸­ï¼Œåˆ™è¡¨æ˜æ¨¡å‹åœ¨è®­ç»ƒæ—¶å¯èƒ½è§è¿‡è¿™ä¸ªè¯„ä¼°æ ·æœ¬ï¼Œå› æ­¤è¿™ä¸ªè¯„ä¼°æ ·æœ¬è¢«è§†ä¸ºâ€œè„æ•°æ®â€ã€‚
- **å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰**
   å›°æƒ‘åº¦è¡¡é‡çš„æ˜¯æ¨¡å‹é¢„æµ‹ç»™å®šæ–‡æœ¬çš„éš¾åº¦ã€‚å¦‚æœä¸€ä¸ªæ¨¡å‹åœ¨è¯„ä¼°æ•°æ®ä¸Šçš„å›°æƒ‘åº¦å¼‚å¸¸ä½ï¼Œæ„å‘³ç€å®ƒå¾ˆå®¹æ˜“é¢„æµ‹è¿™äº›æ–‡æœ¬ï¼Œé‚£ä¹ˆå¾ˆå¯èƒ½å®ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å·²ç»è§è¿‡è¿™äº›æ•°æ®ã€‚

**å¯¹æ¯”æ–¹æ³•ï¼š**
 n-gram é‡å æ–¹æ³•çš„å‡†ç¡®æ€§æ›´é«˜ï¼Œä½†éœ€è¦æ¶ˆè€—å¤§é‡è®¡ç®—èµ„æºï¼Œå› ä¸ºå®ƒéœ€è¦å°†æ¯ä¸ªåŸºå‡†æµ‹è¯•æ ·æœ¬ä¸æ•´ä¸ªè®­ç»ƒæ•°æ®è¿›è¡Œå¯¹æ¯”ï¼Œå› æ­¤å¦‚æœæ— æ³•è®¿é—®è®­ç»ƒæ•°æ®ï¼Œå°±æ— æ³•ä½¿ç”¨è¯¥æ–¹æ³•ã€‚è€Œå›°æƒ‘åº¦æ–¹æ³•è™½ç„¶å‡†ç¡®æ€§è¾ƒä½ï¼Œä½†è®¡ç®—æˆæœ¬æ›´ä½ã€‚

è¿‡å»ï¼Œæœºå™¨å­¦ä¹ æ•™æå»ºè®®ä»è®­ç»ƒæ•°æ®ä¸­ç§»é™¤è¯„ä¼°æ ·æœ¬ï¼Œä»¥ä¿æŒåŸºå‡†æµ‹è¯•çš„æ ‡å‡†åŒ–ï¼Œä»è€Œå¯ä»¥å¯¹ä¸åŒæ¨¡å‹è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚ç„¶è€Œï¼Œåœ¨åŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelsï¼‰æ—¶ä»£ï¼Œå¤§å¤šæ•°äººæ— æ³•æ§åˆ¶è®­ç»ƒæ•°æ®ã€‚å³ä½¿å¯ä»¥æ§åˆ¶è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬ä¹Ÿå¯èƒ½ä¸ä¼šå®Œå…¨ç§»é™¤åŸºå‡†æµ‹è¯•æ•°æ®ï¼Œå› ä¸ºé«˜è´¨é‡çš„åŸºå‡†æ•°æ®èƒ½å¤Ÿæé«˜æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒåŸºå‡†æµ‹è¯•å¾€å¾€æ˜¯åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåæ‰åˆ›å»ºçš„ï¼Œå› æ­¤æ±¡æŸ“çš„è¯„ä¼°æ ·æœ¬å§‹ç»ˆå­˜åœ¨ã€‚

å¯¹äºæ¨¡å‹å¼€å‘è€…è€Œè¨€ï¼Œ**ä¸€ä¸ªå¸¸è§åšæ³•** æ˜¯åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œä»è®­ç»ƒæ•°æ®ä¸­ç§»é™¤ä»–ä»¬å…³å¿ƒçš„åŸºå‡†æµ‹è¯•æ•°æ®ã€‚**ç†æƒ³æƒ…å†µä¸‹**ï¼Œåœ¨æŠ¥å‘Šæ¨¡å‹çš„åŸºå‡†æµ‹è¯•æ€§èƒ½æ—¶ï¼Œåº”æŠ«éœ²è¯¥åŸºå‡†æµ‹è¯•æ•°æ®ä¸­æœ‰å¤šå°‘æ¯”ä¾‹å­˜åœ¨äºè®­ç»ƒæ•°æ®ä¸­ï¼Œä»¥åŠæ¨¡å‹åœ¨æ•´ä¸ªåŸºå‡†æµ‹è¯•é›†å’Œâ€œå¹²å‡€â€æ ·æœ¬ä¸Šçš„è¡¨ç°ã€‚ç„¶è€Œï¼Œç”±äºæ£€æµ‹å’Œå»é™¤æ±¡æŸ“éœ€è¦é¢å¤–çš„å·¥ä½œé‡ï¼Œè®¸å¤šäººé€‰æ‹©è·³è¿‡è¿™ä¸€æ­¥ã€‚

**æ•°æ®æ±¡æŸ“çš„å®ä¾‹ï¼š**
 OpenAI åœ¨åˆ†æ GPT-3 è®­ç»ƒæ•°æ®ä¸­çš„åŸºå‡†æ±¡æŸ“æ—¶å‘ç°ï¼Œ**æœ‰ 13 ä¸ªåŸºå‡†æµ‹è¯•æ•°æ®é›†ä¸­è‡³å°‘ 40% å­˜åœ¨äºè®­ç»ƒæ•°æ®ä¸­**ï¼ˆ[Brown et al., 2020](https://arxiv.org/abs/2005.14165)ï¼‰ã€‚åœ¨ **ä»…ä½¿ç”¨å¹²å‡€æ ·æœ¬è¯„ä¼°** ä¸ **ä½¿ç”¨æ•´ä¸ªåŸºå‡†è¯„ä¼°** ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ï¼Œè§ä¸‹å›¾ï¼š

![differences](images/differences.png)

**åº”å¯¹æ•°æ®æ±¡æŸ“çš„æ–¹æ³•ï¼š**
 ä¸ºäº†åº”å¯¹æ•°æ®æ±¡æŸ“ï¼Œæ’è¡Œæ¦œå¹³å°ï¼ˆå¦‚ Hugging Faceï¼‰é€šå¸¸ä¼šç»˜åˆ¶æ¨¡å‹åœ¨æŸä¸€åŸºå‡†æµ‹è¯•ä¸Šçš„ **æ ‡å‡†å·®**ï¼Œä»¥è¯†åˆ«å¼‚å¸¸æƒ…å†µã€‚æ­¤å¤–ï¼Œå…¬å…±åŸºå‡†æµ‹è¯•åº”ä¿æŒä¸€éƒ¨åˆ†æ•°æ®ç§æœ‰ï¼Œå¹¶æä¾›å·¥å…·ï¼Œä½¿æ¨¡å‹å¼€å‘è€…å¯ä»¥è‡ªåŠ¨é’ˆå¯¹è¿™äº›ç§æœ‰æ•°æ®è¯„ä¼°æ¨¡å‹ã€‚

**å…¬å…±åŸºå‡†æµ‹è¯•å¯ä»¥å¸®åŠ©ç­›é€‰å‡ºä¸åˆæ ¼çš„æ¨¡å‹ï¼Œä½†æ— æ³•å¸®åŠ©æ‰¾åˆ°æœ€é€‚åˆåº”ç”¨çš„æ¨¡å‹**ã€‚å› æ­¤ï¼Œåœ¨ä½¿ç”¨å…¬å…±åŸºå‡†ç¼©å°æ¨¡å‹èŒƒå›´åï¼Œä»éœ€è¦è¿è¡Œ**è‡ªå®šä¹‰è¯„ä¼°æµç¨‹**æ¥æŒ‘é€‰æœ€ä¼˜æ¨¡å‹ã€‚å¦‚ä½•è®¾è®¡è‡ªå®šä¹‰è¯„ä¼°æµç¨‹ï¼Œå°†æ˜¯æ¥ä¸‹æ¥çš„è®¨è®ºä¸»é¢˜ã€‚

## æˆæœ¬ä¸é€Ÿåº¦

åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ï¼Œå¹³è¡¡æ¨¡å‹è´¨é‡ã€å»¶è¿Ÿå’Œæˆæœ¬è‡³å…³é‡è¦ã€‚è™½ç„¶é«˜è´¨é‡çš„è¾“å‡ºæ˜¯ç›®æ ‡ï¼Œä½†å¦‚æœæ¨¡å‹è¿è¡Œç¼“æ…¢ä¸”æˆæœ¬é«˜æ˜‚ï¼Œå…¶å®ç”¨æ€§å°†å¤§æ‰“æŠ˜æ‰£ã€‚å› æ­¤ï¼Œè®¸å¤šå…¬å¸å¯èƒ½é€‰æ‹©è´¨é‡ç¨ä½ä½†åœ¨æˆæœ¬å’Œå»¶è¿Ÿæ–¹é¢æ›´å…·ä¼˜åŠ¿çš„æ¨¡å‹ã€‚

**æˆæœ¬**ï¼šå¯¹äºä½¿ç”¨æ¨¡å‹APIçš„ç”¨æˆ·ï¼Œè´¹ç”¨é€šå¸¸æŒ‰ç”Ÿæˆçš„æ ‡è®°æ•°é‡è®¡ç®—ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„æ ‡è®°è¶Šå¤šï¼Œæˆæœ¬è¶Šé«˜ã€‚å› æ­¤ï¼Œè®¸å¤šåº”ç”¨å°è¯•å‡å°‘è¾“å…¥å’Œè¾“å‡ºæ ‡è®°çš„æ•°é‡ä»¥æ§åˆ¶æˆæœ¬ã€‚å¯¹äºè‡ªè¡Œæ‰˜ç®¡æ¨¡å‹çš„ç”¨æˆ·ï¼Œä¸»è¦æˆæœ¬åœ¨äºè®¡ç®—èµ„æºã€‚ä¸ºäº†å……åˆ†åˆ©ç”¨ç°æœ‰ç¡¬ä»¶èµ„æºï¼Œé€šå¸¸é€‰æ‹©èƒ½åœ¨ç¡¬ä»¶ä¸Šè¿è¡Œçš„æœ€å¤§æ¨¡å‹ã€‚ä¾‹å¦‚ï¼ŒGPUé€šå¸¸å…·æœ‰16 GBã€24 GBã€48 GBå’Œ80 GBçš„å†…å­˜ï¼Œå› æ­¤è®¸å¤šæµè¡Œçš„æ¨¡å‹å‚æ•°æ•°é‡è®¾è®¡ä¸ºé€‚åº”è¿™äº›å†…å­˜é…ç½®ã€‚

**å»¶è¿Ÿ**ï¼šå»¶è¿Ÿä¸ä»…å–å†³äºåº•å±‚æ¨¡å‹ï¼Œè¿˜ä¸æ¯ä¸ªæç¤ºå’Œé‡‡æ ·å˜é‡æœ‰å…³ã€‚è‡ªå›å½’è¯­è¨€æ¨¡å‹é€šå¸¸é€ä¸ªç”Ÿæˆæ ‡è®°ï¼Œç”Ÿæˆçš„æ ‡è®°è¶Šå¤šï¼Œæ€»å»¶è¿Ÿè¶Šé«˜ã€‚å¯ä»¥é€šè¿‡ç²¾å¿ƒè®¾è®¡æç¤ºè¯ï¼ˆä¾‹å¦‚ï¼ŒæŒ‡ç¤ºæ¨¡å‹ç®€æ´ä½œç­”ï¼‰æˆ–è®¾ç½®ç”Ÿæˆçš„åœæ­¢æ¡ä»¶æ¥æ§åˆ¶ç”¨æˆ·æ„ŸçŸ¥çš„æ€»å»¶è¿Ÿã€‚

**å¹³è¡¡**ï¼šåœ¨ä¼˜åŒ–å¤šä¸ªç›®æ ‡æ—¶ï¼Œæ˜ç¡®å“ªäº›ç›®æ ‡å¯ä»¥å¦¥åï¼Œå“ªäº›ä¸å¯ä»¥è‡³å…³é‡è¦ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå»¶è¿Ÿæ˜¯ä¸å¯å¦¥åçš„å› ç´ ï¼Œåº”é¦–å…ˆæ ¹æ®å»¶è¿ŸæœŸæœ›ç­›é€‰æ¨¡å‹ï¼Œæ’é™¤ä¸ç¬¦åˆå»¶è¿Ÿè¦æ±‚çš„æ¨¡å‹ï¼Œç„¶ååœ¨å‰©ä½™æ¨¡å‹ä¸­é€‰æ‹©æœ€ä½³è€…ã€‚è¿™ç§æ–¹æ³•ç±»ä¼¼äºé¡¹ç›®ç®¡ç†ä¸­çš„â€œé“ä¸‰è§’â€åŸåˆ™ï¼Œå³èŒƒå›´ã€æ—¶é—´å’Œæˆæœ¬ä¸‰è€…ä¹‹é—´çš„æƒè¡¡ã€‚

ä¸€ä¸ªç¤ºä¾‹çš„è¦æ±‚å¦‚ä¸‹ï¼š

| **æ ‡å‡†**         | **æŒ‡æ ‡**                    | **åŸºå‡†**           | **ç¡¬æ€§è¦æ±‚**      | **ç†æƒ³æƒ…å†µ**      |
| ---------------- | --------------------------- | ------------------ | ----------------- | ----------------- |
| **æˆæœ¬**         | æ¯è¾“å‡ºæ ‡è®°çš„æˆæœ¬            | X                  | <$30.00 /ç™¾ä¸‡æ ‡è®° | <$15.00 /ç™¾ä¸‡æ ‡è®° |
| **è§„æ¨¡**         | TPMï¼ˆæ¯åˆ†é’Ÿå¤„ç†çš„æ ‡è®°æ•°ï¼‰   | X                  | >100ä¸‡ TPM        | >100ä¸‡ TPM        |
| **å»¶è¿Ÿ**         | Time to First Tokenï¼ˆP90ï¼‰  | å†…éƒ¨ç”¨æˆ·æç¤ºæ•°æ®é›† | <200æ¯«ç§’          | <100æ¯«ç§’          |
| **å»¶è¿Ÿ**         | Time per total queryï¼ˆP90ï¼‰ | å†…éƒ¨ç”¨æˆ·æç¤ºæ•°æ®é›† | <1åˆ†é’Ÿ            | <30ç§’             |
| **æ•´ä½“æ¨¡å‹è´¨é‡** | Elo å¾—åˆ†                    | Chatbot Arena æ’å | >1200             | >1250             |
| **ä»£ç ç”Ÿæˆèƒ½åŠ›** | pass@1                      | HumanEval          | >90%              | >95%              |
| **äº‹å®ä¸€è‡´æ€§**   | å†…éƒ¨ GPT æŒ‡æ ‡               | å†…éƒ¨å¹»è§‰æ•°æ®é›†     | >0.8              | >0.9              |

- **Elo è¯„åˆ†ç³»ç»Ÿ**æ˜¯ä¸€ç§ç”¨äºè¡¡é‡é€‰æ‰‹æˆ–å›¢é˜Ÿç›¸å¯¹æŠ€èƒ½æ°´å¹³çš„è¯„ä»·æ–¹æ³•ï¼Œæœ€åˆç”±åŒˆç‰™åˆ©è£”ç¾å›½ç‰©ç†å­¦å®¶é˜¿å°”å¸•å¾·Â·åŸƒæ´›ï¼ˆArpad Eloï¼‰ä¸ºå›½é™…è±¡æ£‹æ¯”èµ›è®¾è®¡ã€‚å¦‚ä»Šï¼Œè¯¥ç³»ç»Ÿè¢«å¹¿æ³›åº”ç”¨äºå„ç§ç«æŠ€é¢†åŸŸï¼ŒåŒ…æ‹¬å›´æ£‹ã€è¶³çƒã€ç¯®çƒä»¥åŠç”µå­ç«æŠ€ç­‰ã€‚
- **Pass@1** æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°ä»£ç ç”Ÿæˆæ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ï¼Œè¡¡é‡æ¨¡å‹åœ¨ç¬¬ä¸€æ¬¡å°è¯•æ—¶ç”Ÿæˆæ­£ç¡®ä»£ç çš„æ¦‚ç‡ã€‚





## ä½¿ç”¨lm-evaluation-harnessè¯„ä»·æ¨¡å‹ç¿»è¯‘èƒ½åŠ›

**EleutherAI çš„ lm-evaluation-harness**ï¼šå…¶è¯„ä¼°åŸºå‡†çš„ç¤ºä¾‹æ•°é‡ä¸­ä½æ•°ä¸º 1,000ï¼Œå¹³å‡æ•°ä¸º 2,159ã€‚ç»„ç»‡è€…å»ºè®®è¯„ä¼°é›†çš„æœ€å°è§„æ¨¡ä¸º 300 ä¸ªç¤ºä¾‹ï¼Œä½†æ›´å€¾å‘äºè‡³å°‘åŒ…å« 1,000 ä¸ªç¤ºä¾‹ï¼Œç‰¹åˆ«æ˜¯å½“è¿™äº›ç¤ºä¾‹æ˜¯åˆæˆæ—¶ã€‚

1. å®‰è£…

   ```bash
   !pip install git+https://github.com/EleutherAI/lm-evaluation-harness
   ```



2. æŸ¥çœ‹æ”¯æŒçš„æµ‹è¯„ä»»åŠ¡

   ```
   !lm-eval --tasks list
   ```

   è¾“å‡ºï¼š

    ```bash
    |bigbench_salient_translation_error_detection_generate_until   
    ```

   > **[Salient Translation Error Detection](https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/salient_translation_error_detection)** æ˜¯ BIG-bench åŸºå‡†æµ‹è¯•å¥—ä»¶ä¸­çš„ä¸€ä¸ªä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹æ£€æµ‹ç¿»è¯‘ä¸­æ˜¾è‘—é”™è¯¯çš„èƒ½åŠ›ã€‚è¯¥ä»»åŠ¡çš„ç›®æ ‡æ˜¯ç¡®å®šæ¨¡å‹æ˜¯å¦èƒ½å¤Ÿè¯†åˆ«ç¿»è¯‘æ–‡æœ¬ä¸­çš„å…³é”®é”™è¯¯ï¼Œç¡®ä¿è¯‘æ–‡çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚ç›®å‰è¿™ä¸ªæµ‹è¯•é›†åªæ”¯æŒå¾·æ–‡å’Œè‹±æ–‡çš„ç¿»è¯‘èƒ½åŠ›æµ‹è¯„ã€‚
   >
   > **ä»»åŠ¡ç‰¹ç‚¹ï¼š**
   >
   > - **é”™è¯¯ç±»å‹**ï¼šæ¨¡å‹éœ€è¦æ£€æµ‹ç¿»è¯‘ä¸­çš„å„ç§é”™è¯¯ç±»å‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šæ•°å€¼é”™è¯¯ã€å‘½åå®ä½“é”™è¯¯ã€å¦å®šæˆ–åä¹‰è¯ä½¿ç”¨é”™è¯¯ã€ä¿®é¥°è¯­æˆ–å½¢å®¹è¯ä½¿ç”¨é”™è¯¯ã€å†…å®¹é—æ¼ä»¥åŠäº‹å®æ€§é”™è¯¯ã€‚
   > - **è¯„ä¼°æŒ‡æ ‡**ï¼šä¸»è¦ä½¿ç”¨å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰ç­‰æŒ‡æ ‡æ¥è¡¡é‡æ¨¡å‹åœ¨æ£€æµ‹ç¿»è¯‘é”™è¯¯æ–¹é¢çš„æ€§èƒ½ã€‚

3. è¯„ä¼°metaçš„mbartçš„å¾·è‹±ç¿»è¯‘èƒ½åŠ›

   ```bash
   !lm-eval --model hf \
       --model_args pretrained=facebook/mbart-large-50,trust_remote_code=True \
       --tasks bigbench_salient_translation_error_detection_generate_until \
       --device cuda:0 \
       --batch_size 8 \
       --output_path /content/lm_eval_results3
   
   ```

   è¾“å‡ºï¼š

   | Tasks                                                       | Version | Filter | n-shot | Metric      |      |  Value |      | Stderr |
   | ----------------------------------------------------------- | ------: | ------ | -----: | ----------- | ---- | -----: | ---- | -----: |
   | bigbench_salient_translation_error_detection_generate_until |     1.0 | none   |      0 | exact_match | â†‘    | 0.0000 | Â±    | 0.0000 |

4. å¯¹ç…§GPT-4oçš„å¾·è‹±ç¿»è¯‘èƒ½åŠ›

   ```
   !pip install tiktoken
   
   import os
   os.environ['OPENAI_API_KEY'] = 'your-api-key'
   
   ```

   

   ```
   !lm_eval --model openai-chatcompletions \
           --model_args model=gpt-4o \
           --tasks bigbench_salient_translation_error_detection_generate_until \
           --device cuda:0 \
           --batch_size 8 \
           --output_path /content/lm_eval_results4
   
   ```

   è¾“å‡ºç»“æœï¼š
   openai-chat-completions (model=gpt-4o), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 1

   | Tasks                                                       | Version | Filter | n-shot | Metric      |      |  Value |      | Stderr |
   | ----------------------------------------------------------- | ------: | ------ | -----: | ----------- | ---- | -----: | ---- | -----: |
   | bigbench_salient_translation_error_detection_generate_until |       1 | none   |      0 | exact_match | â†‘    | 0.0341 | Â±    | 0.0057 |



### å…¶ä»–ä»»åŠ¡

`lm-eval`é¢„åˆ¶äº†éå¸¸å¤šçš„ä»»åŠ¡ï¼Œå…·ä½“å¯ä»¥é€šè¿‡ä¸‹æ–¹æŒ‡ä»¤æŸ¥è¯¢

```bash
!lm-eval --tasks list
```



è¾“å‡ºçš„éƒ¨åˆ†ç»“æœå¦‚ä¸‹ï¼Œ

| Task                                                    | Path                                                         | Type            |
| ------------------------------------------------------- | ------------------------------------------------------------ | --------------- |
| bigbench_mathematical_induction_multiple_choice         | lm_eval/tasks/bigbench/multiple_choice/mathematical_induction.yaml | multiple_choice |
| bigbench_matrixshapes_generate_until                    | lm_eval/tasks/bigbench/generate_until/matrixshapes.yaml      | generate_until  |
| bigbench_metaphor_boolean_generate_until                | lm_eval/tasks/bigbench/generate_until/metaphor_boolean.yaml  | generate_until  |
| bigbench_metaphor_boolean_multiple_choice               | lm_eval/tasks/bigbench/multiple_choice/metaphor_boolean.yaml | multiple_choice |
| bigbench_metaphor_understanding_generate_until          | lm_eval/tasks/bigbench/generate_until/metaphor_understanding.yaml | generate_until  |
| bigbench_metaphor_understanding_multiple_choice         | lm_eval/tasks/bigbench/multiple_choice/metaphor_understanding.yaml | multiple_choice |
| bigbench_minute_mysteries_qa_generate_until             | lm_eval/tasks/bigbench/generate_until/minute_mysteries_qa.yaml | generate_until  |
| bigbench_misconceptions_generate_until                  | lm_eval/tasks/bigbench/generate_until/misconceptions.yaml    | generate_until  |
| bigbench_misconceptions_multiple_choice                 | lm_eval/tasks/bigbench/multiple_choice/misconceptions.yaml   | multiple_choice |
| bigbench_misconceptions_russian_generate_until          | lm_eval/tasks/bigbench/generate_until/misconceptions_russian.yaml | generate_until  |
| bigbench_misconceptions_russian_multiple_choice         | lm_eval/tasks/bigbench/multiple_choice/misconceptions_russian.yaml | multiple_choice |
| bigbench_mnist_ascii_generate_until                     | lm_eval/tasks/bigbench/generate_until/mnist_ascii.yaml       | generate_until  |
| bigbench_mnist_ascii_multiple_choice                    | lm_eval/tasks/bigbench/multiple_choice/mnist_ascii.yaml      | multiple_choice |
| bigbench_modified_arithmetic_generate_until             | lm_eval/tasks/bigbench/generate_until/modified_arithmetic.yaml | generate_until  |
| bigbench_moral_permissibility_generate_until            | lm_eval/tasks/bigbench/generate_until/moral_permissibility.yaml | generate_until  |
| bigbench_moral_permissibility_multiple_choice           | lm_eval/tasks/bigbench/multiple_choice/moral_permissibility.yaml | multiple_choice |
| bigbench_movie_dialog_same_or_different_generate_until  | lm_eval/tasks/bigbench/generate_until/movie_dialog_same_or_different.yaml | generate_until  |
| bigbench_movie_dialog_same_or_different_multiple_choice | lm_eval/tasks/bigbench/multiple_choice/movie_dialog_same_or_different.yaml | multiple_choice |
| bigbench_movie_recommendation_generate_until            | lm_eval/tasks/bigbench/generate_until/movie_recommendation.yaml | generate_until  |
| bigbench_movie_recommendation_multiple_choice           | lm_eval/tasks/bigbench/multiple_choice/movie_recommendation.yaml | multiple_choice |
| bigbench_mult_data_wrangling_generate_until             | lm_eval/tasks/bigbench/generate_until/mult_data_wrangling.yaml | generate_until  |
| bigbench_multiemo_generate_until                        | lm_eval/tasks/bigbench/generate_until/multiemo.yaml          | generate_until  |
| bigbench_multiemo_multiple_choice                       | lm_eval/tasks/bigbench/multiple_choice/multiemo.yaml         | multiple_choice |
| bigbench_natural_instructions_generate_until            | lm_eval/tasks/bigbench/generate_until/natural_instructions.yaml | generate_until  |

å…¶ä»–ä»»åŠ¡çš„éƒ¨åˆ†ä»‹ç»å¦‚ä¸‹ï¼šå…·ä½“çš„ä»»åŠ¡ä»‹ç»å¯è§ï¼š[Tasks](https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/README.md)

| ä»»åŠ¡ç³»åˆ—                    | æè¿°                                                         | è¯­è¨€                     |
| --------------------------- | ------------------------------------------------------------ | ------------------------ |
| aclue                       | ä¸“æ³¨äºå¤ä»£æ±‰è¯­ç†è§£åŠæ–‡åŒ–æ–¹é¢çš„ä»»åŠ¡ã€‚                         | å¤æ±‰è¯­                   |
| aexams                      | ä¸å„ç§å­¦ç§‘è€ƒè¯•ç›¸å…³çš„é˜¿æ‹‰ä¼¯è¯­ä»»åŠ¡ã€‚                           | é˜¿æ‹‰ä¼¯è¯­                 |
| agieval                     | æ¶‰åŠå†å²æ•°æ®æˆ–ä¸å†å²åŠå†å²æ–‡æœ¬ç›¸å…³é—®é¢˜çš„ä»»åŠ¡ã€‚               | è‹±è¯­ï¼Œä¸­æ–‡               |
| anli                        | å¯¹æŠ—æ€§è‡ªç„¶è¯­è¨€æ¨ç†ä»»åŠ¡ï¼Œç”¨ä»¥æµ‹è¯•æ¨¡å‹é²æ£’æ€§ã€‚                 | è‹±è¯­                     |
| arabic_leaderboard_complete | å¼€æ”¾é˜¿æ‹‰ä¼¯è¯­å¤§è¯­è¨€æ¨¡å‹æ’è¡Œæ¦œä¸­ä»»åŠ¡çš„å®Œæ•´ç‰ˆï¼Œä¾§é‡äºè¯„ä¼°åæ˜ é˜¿æ‹‰ä¼¯è¯­ç†è§£ã€é¢†ä¼šã€æ–‡åŒ–å’Œé—äº§ç‰¹ç‚¹çš„æ¨¡å‹ã€‚æ³¨æ„ï¼Œå…¶ä¸­ä¸€äº›ä»»åŠ¡æ˜¯æœºå™¨ç¿»è¯‘çš„ã€‚ | é˜¿æ‹‰ä¼¯è¯­ï¼ˆéƒ¨åˆ†æœºå™¨ç¿»è¯‘ï¼‰ |
| arabic_leaderboard_light    | å¼€æ”¾é˜¿æ‹‰ä¼¯è¯­å¤§è¯­è¨€æ¨¡å‹æ’è¡Œæ¦œä¸­ä»»åŠ¡çš„ç®€åŒ–ç‰ˆï¼ˆå³åŸåŸºå‡†æµ‹è¯•é›†çš„10%æ ·æœ¬ï¼‰ï¼Œä¾§é‡äºè¯„ä¼°åæ˜ é˜¿æ‹‰ä¼¯è¯­ç†è§£ã€é¢†ä¼šã€æ–‡åŒ–å’Œé—äº§ç‰¹ç‚¹çš„æ¨¡å‹ã€‚æ³¨æ„ï¼Œå…¶ä¸­ä¸€äº›ä»»åŠ¡æ˜¯æœºå™¨ç¿»è¯‘çš„ã€‚ | é˜¿æ‹‰ä¼¯è¯­ï¼ˆéƒ¨åˆ†æœºå™¨ç¿»è¯‘ï¼‰ |



## ç»“æœè§£è¯»

ä¸€å¼€å§‹æˆ‘ä»¥ä¸ºåªæ˜¯metaçš„æ¨¡å‹èƒ½åŠ›ä¸€èˆ¬ï¼Œç„¶åå°±å°è¯•äº†ä½¿ç”¨gpt-4oï¼Œå…¶æ­£ç¡®ç‡ä¾ç„¶ä½å¾—å“äººï¼Œäºæ˜¯æˆ‘ä»”ç»†çœ‹äº†ä¸€ä¸‹åˆ†æç»“æœã€‚



### æ•°æ®é›†

å¾·æ–‡å¥å­çš„æ¥æºå¦‚ä¸‹ï¼šä¸€ç»„æè¿°ï¼ˆæ®µè½ï¼‰ä» [WIT](https://github.com/google-research-datasets/wit) æ•°æ®é›†ä¸­æŠ½æ ·è·å¾—ã€‚åˆ©ç”¨å¥å­åˆ†å‰²å™¨ï¼ˆStanzaï¼‰æå–äº†æè¿°çš„ç¬¬ä¸€å¥ã€‚éšåï¼Œåˆ©ç”¨å•†ä¸šç¿»è¯‘æœåŠ¡å°†å¥å­ç¿»è¯‘æˆè‹±æ–‡ã€‚éšåï¼Œå°†è¿™äº›å¥å­å¯¹ï¼ˆåŸæ–‡ã€è¯‘æ–‡ï¼‰æä¾›ç»™äººå·¥è¯„å®¡ï¼Œå¹¶é™„ä¸Šå¦‚ä¸‹æŒ‡ç¤ºï¼šåœ¨ç¿»è¯‘ä¸­å¼•å…¥å…­ç±»é”™è¯¯ä¸­çš„ä¸€ç§ï¼ŒåŒæ—¶å°½é‡ä¸å½±å“ç¿»è¯‘çš„æµç•…æ€§ã€‚



ç¤ºä¾‹æ•°æ®ï¼š

```json
{
        "input": "Source: Das EinkÃ¶pfige Ferkelkraut ist eine Pflanzenart aus der Gattung der FerkelkrÃ¤uter innerhalb der Familie der KorbblÃ¼tler.\nTranslation: The two-headed piglet herb is a species of herb in the family.\nThe translation contains an error pertaining to ",
        "target_scores": {
         "Modifiers or Adjectives": 0,
         "Numerical Values": 1,
         "Negation or Antonyms": 0,
         "Named Entities": 0,
         "Dropped Content": 0,
         "Facts": 0
        }
```



### ä½¿ç”¨Chatgpt o1 å®éªŒï¼š

æµ‹è¯•é›†æ ‡æ³¨çš„æ˜¯ï¼š"Numerical Values": 1,

æç¤ºè¯ï¼š

```md
"input": "Source: Der MÃ¼ggenburger Zollhafen ist ein Hafenbecken in Hamburg-Veddel.\nTranslation: The MÃ¼ggenburg Harbour is a dock in Hamburg-Veddel, Germany.\nThe translation contains an error pertaining to ",
        "target_scores": {
         "Modifiers or Adjectives": 0,
         "Numerical Values": 0,
         "Negation or Antonyms": 0,
         "Named Entities": 0,
         "Dropped Content": 0,
         "Facts": 0

Please try to find the error in the input and increase the counter in its corresponding error category.
```

è¾“å‡ºï¼š

```md
Analysis of the source and translation:

    Source (German):
    Der MÃ¼ggenburger Zollhafen ist ein Hafenbecken in Hamburg-Veddel.
    Literally: â€œThe MÃ¼ggenburger Zollhafen is a harbor basin in Hamburg-Veddel.â€

    Translation (English):
    The MÃ¼ggenburg Harbour is a dock in Hamburg-Veddel, Germany.

The term â€œMÃ¼ggenburger Zollhafenâ€ is a specific named entity. In the translation, it was changed to â€œMÃ¼ggenburg Harbour,â€ and the word â€œZollâ€ (â€œcustomsâ€) was dropped entirely. Because â€œMÃ¼ggenburger Zollhafenâ€ is the proper name for that port facility, losing â€œZollâ€ is effectively an error in translating or preserving the named entity.

Relevant error category: â€œNamed Entitiesâ€

Since the specific name (MÃ¼ggenburger Zollhafen) was altered and partially dropped (â€œZollhafenâ€ â†’ â€œHarbourâ€), this counts as a mistake in handling a named entity. Therefore, you would increment the counter for Named Entities by 1.
```

ä½¿ç”¨ChatGPT å¤šæ¬¡æŸ¥è¯åå‘ç°ï¼šåŸè¯‘æ–‡å°†â€œHafenbeckenâ€é”™è¯¯åœ°è¯‘ä¸ºâ€œdockâ€ï¼Œè€Œâ€œHafenbeckenâ€æŒ‡çš„æ˜¯â€œæ¸¯å£æ°´åŸŸâ€æˆ–â€œæ¸¯å£ç›†åœ°â€ï¼Œè€Œä¸æ˜¯â€œç å¤´â€ã€‚å› æ­¤ï¼Œo3-miniè®¤ä¸ºè¿™ä¸€é”™è¯¯å±äºäº‹å®é”™è¯¯ï¼Œo1è®¤ä¸ºæ˜¯ä¸€ä¸ªå®ä½“è¯†åˆ«çš„é”™è¯¯ã€‚ä½†æ˜¯ç­”æ¡ˆè®¤ä¸ºæ˜¯ä¸€ä¸ªæ•°å€¼é”™è¯¯ã€‚

æ€»ä¹‹ï¼Œäººå·¥æ ‡è®°è€…çš„é€»è¾‘å’Œæ¨¡å‹çš„é€»è¾‘ä¸æ˜¯å¾ˆåŒ¹é…ï¼Œè¯¥æ•°æ®é›†ä½œè€…ä¹Ÿæœªæ›¾é€šè¿‡å…¶ä»–æ–¹å¼è¯å®ä»–ä»¬æ‰€æä¾›æ•°æ®é›†çš„å¯é æ€§ã€‚è¿™ä¹Ÿæ˜¯è¿™ç±»æ•°æ®é›†çš„é€šç”¨é—®é¢˜ï¼Œäººå·¥æ„å»ºçš„æ•°æ®é›†éšæ„æ€§å¤§ï¼Œåç»­åœ¨ä½¿ç”¨æ•°æ®é›†æ—¶è¦æ³¨æ„é€‰æ‹©æƒå¨å¯é çš„æ¥æºã€‚



